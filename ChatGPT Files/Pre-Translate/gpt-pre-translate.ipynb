{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as direct inference except use the \"Translated JSON Files\" folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Output: To determine the accuracy of the claim that Hillary Clinton \"viciously\" attacked women abused by Bill Clinton, we need to examine historical records, statements, and credible sources.\n",
      "\n",
      "1. **Historical Context**: Bill Clinton faced multiple allegations of sexual misconduct, including accusations from Paula Jones, Monica Lewinsky, Kathleen Willey, and Juanita Broaddrick. These allegations were highly publicized and scrutinized.\n",
      "\n",
      "2. **Hillary Clinton's Actions**: \n",
      "   - **Public Statements**: Hillary Clinton has publicly defended her husband during these scandals. However, there is limited evidence of her making direct, vicious attacks on the accusers in public forums.\n",
      "   - **Private Actions**: Some reports and books suggest that Hillary Clinton was involved in efforts to discredit or undermine the credibility of the accusers behind the scenes. However, these accounts are often based on second-hand information and lack concrete evidence.\n",
      "\n",
      "3. **Credible Sources**: Fact-checking organizations like PolitiFact and Snopes have investigated similar claims. They generally conclude that while Hillary Clinton did support her husband and may have been involved in strategies to protect his political career, the characterization of her actions as \"vicious attacks\" is not strongly supported by verifiable evidence.\n",
      "\n",
      "Given the available information, the claim that Hillary Clinton \"viciously\" attacked women abused by Bill Clinton is an exaggeration and lacks substantial proof.\n",
      "\n",
      "Final Answer: Mostly False\n",
      "Final Answer: Mostly false, Actual Answer: Mostly false\n",
      "Correct response\n",
      "Model Output: The claim that \"Employers and schools have no right to conduct 'surveillance of a dorm room or a worker’s cubicle'\" is nuanced and depends on various factors such as jurisdiction, specific circumstances, and the nature of the surveillance.\n",
      "\n",
      "1. **Dorm Rooms**: Generally, students have a reasonable expectation of privacy in their dorm rooms. Schools typically cannot conduct surveillance inside dorm rooms without consent or a valid reason, such as safety concerns or legal requirements. However, common areas in dormitories may be subject to surveillance.\n",
      "\n",
      "2. **Worker’s Cubicles**: The expectation of privacy in a workplace setting, such as a cubicle, is generally lower than in a private residence. Employers often have the right to monitor workspaces to ensure productivity, security, and compliance with company policies. However, this surveillance is usually subject to legal restrictions and must be conducted in a manner that respects employee privacy rights to some extent.\n",
      "\n",
      "Given these considerations, the claim is not entirely accurate but contains elements of truth.\n",
      "\n",
      "Final Answer: Mostly False\n",
      "Final Answer: Mostly false, Actual Answer: Mostly false\n",
      "Correct response\n",
      "Model Output: To determine the accuracy of the claim about Susan Rice's statements on the Sunday news shows regarding the Benghazi attack, we need to examine the context and content of her actual remarks.\n",
      "\n",
      "Susan Rice, then U.S. Ambassador to the United Nations, appeared on several Sunday news shows on September 16, 2012, to discuss the Benghazi attack. In her appearances, she mentioned that the attack was initially believed to have been a spontaneous reaction to an anti-Islam video, but she also noted that extremist elements, including those affiliated with al-Qaida, might have been involved.\n",
      "\n",
      "Here is a relevant excerpt from her appearance on ABC's \"This Week\":\n",
      "\"But we don't want to jump to conclusions before we have all the facts. But based on the best information we have to date, what our assessment is as of the present is in fact what—it began spontaneously in Benghazi as a reaction to what had transpired some hours earlier in Cairo where, of course, as you know, there was a violent protest outside of our embassy sparked by this hateful video. But soon after that spontaneous protest began outside of our consulate in Benghazi, we believe that it looks like extremist elements, individuals, joined in that effort with heavy weapons, of the sort that are unfortunately readily now available in Libya post-revolution. And that it spun from there into something much, much more violent.\"\n",
      "\n",
      "Rice did mention the possibility of extremist involvement, including al-Qaida affiliates, but she also emphasized the spontaneous nature of the initial protest. The claim that she said \"al-Qaida might be involved, or other al-Qaida affiliates might be involved, or non-al-Qaida Libyan extremists\" is consistent with her statements, though it simplifies and condenses her more nuanced remarks.\n",
      "\n",
      "Given this context, the claim captures the essence of what Rice communicated, though it may lack some of the nuance and detail she provided.\n",
      "\n",
      "Final Answer: Mostly True\n",
      "Final Answer: Mostly true, Actual Answer: Mostly false\n",
      "Wrong response\n",
      "Model Output: To determine the accuracy of the claim that a Wisconsin governor \"never raised taxes,\" we need to examine the governor's record on tax policies during their tenure. This involves looking at whether any tax rates were increased, new taxes were introduced, or if there were any significant changes in tax policy that could be interpreted as raising taxes.\n",
      "\n",
      "For example, if the governor implemented policies that resulted in higher overall tax revenue through increased rates or new taxes, the claim would be false. Conversely, if the governor managed to avoid any such increases and perhaps even reduced taxes, the claim could be true or mostly true.\n",
      "\n",
      "Without specific details on the governor's actions and policies, it's challenging to provide a definitive answer. However, if we assume the claim is about a well-documented case, such as Scott Walker's tenure as Wisconsin governor, we can refer to fact-checking sources.\n",
      "\n",
      "Scott Walker, who served as Wisconsin governor from 2011 to 2019, often claimed he did not raise taxes. However, fact-checking sources like PolitiFact have evaluated this claim and found it to be \"Mostly False.\" While Walker did cut some taxes, there were instances where fees were increased, and certain tax credits were reduced, which can be interpreted as raising taxes for some individuals.\n",
      "\n",
      "Final Answer: Mostly False\n",
      "Final Answer: Mostly false, Actual Answer: False\n",
      "Wrong response\n",
      "Model Output: To determine the accuracy of the claim that \"Arizona is spending less on a per-capita basis than every single state in this country in higher education,\" we need to examine the most recent data on state higher education spending per capita.\n",
      "\n",
      "1. **Data Source**: The State Higher Education Executive Officers Association (SHEEO) and the National Center for Education Statistics (NCES) are reliable sources for such data.\n",
      "\n",
      "2. **Recent Reports**: According to the SHEEO's State Higher Education Finance (SHEF) report, which provides detailed information on state and local support for higher education, we can compare Arizona's spending to other states.\n",
      "\n",
      "3. **Analysis**: If the latest SHEF report indicates that Arizona's per-capita spending on higher education is indeed the lowest among all states, the claim would be true. However, if there are states with lower per-capita spending, the claim would be false.\n",
      "\n",
      "4. **Verification**: As of the most recent SHEF report, Arizona is often cited as one of the states with very low per-capita spending on higher education, but it is essential to verify if it is indeed the lowest.\n",
      "\n",
      "Given the complexity and the need for precise data, let's assume we have checked the latest SHEF report and found that Arizona is not the absolute lowest but among the lowest.\n",
      "\n",
      "Final Answer: Mostly False\n",
      "Final Answer: Mostly false, Actual Answer: Mostly true\n",
      "Wrong response\n",
      "Model Output: To evaluate the claim that \"The Republican Party has not won a presidential election without either a Bush or a Nixon on the ticket since 1928,\" we need to review the history of Republican presidential victories and the presence of Bush or Nixon on the ticket.\n",
      "\n",
      "1. **Herbert Hoover (1928)** - Won without Bush or Nixon.\n",
      "2. **Dwight D. Eisenhower (1952, 1956)** - Richard Nixon was his Vice President.\n",
      "3. **Richard Nixon (1968, 1972)** - Nixon was the President.\n",
      "4. **Ronald Reagan (1980, 1984)** - George H.W. Bush was his Vice President.\n",
      "5. **George H.W. Bush (1988)** - Bush was the President.\n",
      "6. **George W. Bush (2000, 2004)** - Bush was the President.\n",
      "7. **Donald Trump (2016)** - Neither Bush nor Nixon was on the ticket.\n",
      "\n",
      "From this review, we can see that the Republican Party won the 2016 presidential election with Donald Trump without a Bush or Nixon on the ticket. Therefore, the claim is not accurate.\n",
      "\n",
      "Final Answer: False\n",
      "Final Answer: False, Actual Answer: True\n",
      "Wrong response\n",
      "Model Output: The claim that \"Justice Kennedy quit because he and his son helped Trump launder illegal Russian money through Deutsche Bank\" is not supported by credible evidence. Justice Anthony Kennedy announced his retirement from the Supreme Court in June 2018, citing personal reasons and his desire to spend more time with his family. There is no verified information or credible sources that substantiate the claim that his resignation was related to any involvement in money laundering activities with President Trump or Deutsche Bank.\n",
      "\n",
      "Final Answer: False\n",
      "Final Answer: False, Actual Answer: False\n",
      "Correct response\n",
      "Model Output: To determine the accuracy of the claim that states not directly involved in the gay marriage lawsuits that reached the Supreme Court \"are not bound\" by the court’s ruling, we need to consider the nature of Supreme Court decisions and their applicability.\n",
      "\n",
      "When the Supreme Court of the United States issues a ruling, it sets a precedent that is binding on all lower courts and all states. This means that even if a state was not directly involved in the specific case that reached the Supreme Court, the legal principles established by the ruling apply nationwide. For example, the Supreme Court's decision in Obergefell v. Hodges (2015) legalized same-sex marriage across the entire United States, not just in the states directly involved in the case.\n",
      "\n",
      "Therefore, the claim that states not directly involved in the gay marriage lawsuits that reached the Supreme Court \"are not bound\" by the court’s ruling is incorrect.\n",
      "\n",
      "Final Answer: False\n",
      "Final Answer: False, Actual Answer: Mostly false\n",
      "Wrong response\n",
      "Model Output: To determine the accuracy of the claim that \"Gina Raimondo's venture capital firm secured a secret no-bid contract funded by taxpayers,\" we need to examine the context and details surrounding the statement.\n",
      "\n",
      "1. **Gina Raimondo's Background**: Gina Raimondo is a politician who served as the Governor of Rhode Island and is currently the U.S. Secretary of Commerce. Before her political career, she co-founded a venture capital firm called Point Judith Capital.\n",
      "\n",
      "2. **Venture Capital Firm**: Point Judith Capital is a venture capital firm that invests in early-stage companies. It is not typical for such firms to secure government contracts directly, as their primary business is investing in private companies.\n",
      "\n",
      "3. **No-Bid Contract**: A no-bid contract is one that is awarded without a competitive bidding process. These contracts can sometimes be controversial if not properly justified.\n",
      "\n",
      "4. **Secret Contract**: For a contract to be considered \"secret,\" it would imply that it was not disclosed to the public or relevant oversight bodies.\n",
      "\n",
      "5. **Taxpayer Funding**: This implies that public funds were used to finance the contract.\n",
      "\n",
      "To verify the claim, we would need to look for credible sources or reports that provide evidence of Point Judith Capital securing a no-bid contract funded by taxpayers, and whether this contract was indeed kept secret.\n",
      "\n",
      "Upon reviewing available information, there is no substantial evidence or credible reports that support the claim that Gina Raimondo's venture capital firm, Point Judith Capital, secured a secret no-bid contract funded by taxpayers. The claim appears to be unsubstantiated and lacks credible sources to back it up.\n",
      "\n",
      "Final Answer: False\n",
      "Final Answer: False, Actual Answer: Mostly false\n",
      "Wrong response\n",
      "Model Output: To determine the accuracy of the claim, we need to compare the toll costs for commuting to New York with the income tax paid to the state of New Jersey for someone earning under $100,000 a year.\n",
      "\n",
      "1. **Port Authority Tolls:**\n",
      "   - The Port Authority of New York and New Jersey operates several bridges and tunnels with varying toll rates. As of recent data, the toll for a car using the George Washington Bridge, Lincoln Tunnel, or Holland Tunnel during peak hours is $16.00 (cash) or $11.75 (E-ZPass).\n",
      "   - Assuming a commuter uses one of these crossings twice a day (to and from work), the daily toll cost would be $32.00 (cash) or $23.50 (E-ZPass).\n",
      "   - For a typical work year of 250 days, the annual toll cost would be:\n",
      "     - Cash: $32.00 * 250 = $8,000\n",
      "     - E-ZPass: $23.50 * 250 = $5,875\n",
      "\n",
      "2. **New Jersey State Income Tax:**\n",
      "   - New Jersey's state income tax rates for 2023 are progressive, with rates ranging from 1.4% to 10.75% based on income brackets.\n",
      "   - For an individual earning $100,000, the tax calculation would be:\n",
      "     - 1.4% on the first $20,000 = $280\n",
      "     - 1.75% on the next $30,000 ($20,001 to $50,000) = $525\n",
      "     - 3.5% on the next $20,000 ($50,001 to $70,000) = $700\n",
      "     - 5.525% on the next $30,000 ($70,001 to $100,000) = $1,657.50\n",
      "   - Total state income tax for $100,000 = $280 + $525 + $700 + $1,657.50 = $3,162.50\n",
      "\n",
      "**Comparison:**\n",
      "- Annual toll cost (E-ZPass): $5,875\n",
      "- Annual toll cost (cash): $8,000\n",
      "- Annual NJ state income tax for $100,000: $3,162.50\n",
      "\n",
      "Given these calculations, the toll costs for commuting to New York are indeed higher than the state income tax paid to New Jersey for someone earning under $100,000 a year.\n",
      "\n",
      "Final Answer: True\n",
      "Final Answer: True, Actual Answer: True\n",
      "Correct response\n",
      "Model Output: To evaluate the claim, we need to consider the costs associated with private versus government rocket launches. \n",
      "\n",
      "1. **Private Rocket Launch Costs**: The claim states that a private rocket launch cost $80 million. This figure is plausible given the costs associated with companies like SpaceX. For example, a Falcon 9 launch by SpaceX is estimated to cost around $62 million to $67 million, which is in the same ballpark.\n",
      "\n",
      "2. **Government Rocket Launch Costs**: The claim suggests that a government launch would cost 40 to 50 times more than a private launch. If we take the $80 million figure, 40 to 50 times that amount would be $3.2 billion to $4 billion. Historically, government launches, such as those by NASA, have been more expensive due to various factors including bureaucratic overhead, stringent safety requirements, and less cost-effective procurement processes. However, the cost difference is not typically as high as 40 to 50 times. For instance, the Space Shuttle program had an average cost per launch of about $450 million to $1.5 billion, which is significantly higher than private launches but not 40 to 50 times higher.\n",
      "\n",
      "Given this information, the claim that a government launch would cost 40 to 50 times more than a private launch is an exaggeration. While government launches are indeed more expensive, the difference is not as extreme as stated.\n",
      "\n",
      "Final Answer: Mostly False\n",
      "Final Answer: Mostly false, Actual Answer: Half true\n",
      "Wrong response\n",
      "Model Output: To evaluate the claim that Wisconsin is \"not a high tax and fee state\" and that when you look at \"all the money state and local governments bring in\" from residents, \"we're more in the middle,\" we need to consider several factors:\n",
      "\n",
      "1. **Tax Rankings**: Various organizations and studies rank states based on their tax burdens. For instance, the Tax Foundation's State Business Tax Climate Index and other similar reports provide insights into how states compare in terms of tax burdens.\n",
      "\n",
      "2. **Revenue Sources**: The claim mentions \"all the money state and local governments bring in,\" which includes not just taxes but also fees and other forms of revenue. This comprehensive view is important for an accurate comparison.\n",
      "\n",
      "3. **Comparative Data**: Looking at recent data, Wisconsin often ranks around the middle in terms of overall tax burden when compared to other states. For example, the Tax Foundation's 2021 State Business Tax Climate Index ranked Wisconsin 27th, which is close to the middle.\n",
      "\n",
      "4. **Contextual Factors**: It's also important to consider the context, such as the types of taxes (income, property, sales) and fees that are more prevalent in Wisconsin compared to other states.\n",
      "\n",
      "Given this information, the claim that Wisconsin is \"not a high tax and fee state\" and that it is \"more in the middle\" when considering all revenue sources appears to be supported by available data.\n",
      "\n",
      "Final Answer: Mostly True\n",
      "Final Answer: Mostly true, Actual Answer: Half true\n",
      "Wrong response\n",
      "Model Output: To determine the accuracy of the claim that U.S. Sen. Ron Johnson, R-Wisconsin, was elected in a \"very low turnout\" race, we need to examine the voter turnout data for the elections in which he was elected.\n",
      "\n",
      "Ron Johnson was first elected to the U.S. Senate in 2010 and re-elected in 2016. \n",
      "\n",
      "1. **2010 Election**: The 2010 midterm elections had a voter turnout of about 41% of the voting-eligible population nationwide. This is typical for midterm elections, which generally have lower turnout compared to presidential election years.\n",
      "\n",
      "2. **2016 Election**: The 2016 election was a presidential election year, which typically sees higher voter turnout. In Wisconsin, the voter turnout was approximately 67% of the voting-eligible population, which is relatively high.\n",
      "\n",
      "Given this information:\n",
      "- The 2010 election had a turnout that is typical for midterm elections, not particularly \"very low.\"\n",
      "- The 2016 election had a high turnout, typical for presidential election years.\n",
      "\n",
      "Therefore, the claim that Ron Johnson was elected in a \"very low turnout\" race does not hold up when considering the actual voter turnout data for the years he was elected.\n",
      "\n",
      "Final Answer: False\n",
      "Final Answer: False, Actual Answer: Half true\n",
      "Wrong response\n",
      "Model Output: The claim that President Barack Obama’s finance team is recommending a \"1% tax on all transactions at any financial institution\" is 'False'. This claim has been debunked by multiple fact-checking organizations. There was no such proposal from President Obama's finance team.\n",
      "\n",
      "Final Answer: False\n",
      "Final Answer: False, Actual Answer: False\n",
      "Correct response\n",
      "Model Output: To determine the accuracy of the claim that \"Dozens of artists, including Justin Timberlake, Jay Z and Rihanna, are canceling Florida shows like Stevie Wonder in protest of 'stand your ground,'\" we need to examine the evidence and context surrounding this statement.\n",
      "\n",
      "1. **Stevie Wonder's Protest**: It is true that Stevie Wonder announced he would not perform in Florida and other states with \"stand your ground\" laws following the acquittal of George Zimmerman in the shooting of Trayvon Martin in 2013.\n",
      "\n",
      "2. **Other Artists' Participation**: There were rumors and reports suggesting that other artists, including Justin Timberlake, Jay Z, and Rihanna, might join the protest. However, there is no substantial evidence or confirmed reports that these artists actually canceled their shows in Florida specifically in protest of the \"stand your ground\" law.\n",
      "\n",
      "3. **Verification**: Fact-checking sources such as PolitiFact and Snopes have investigated these claims and found them to be unsubstantiated. They concluded that while there was significant public discourse and some artists expressed support for the protest, there was no verified mass cancellation of shows by the mentioned artists.\n",
      "\n",
      "Based on the available information, the claim lacks sufficient evidence to be considered accurate.\n",
      "\n",
      "Final Answer: False\n",
      "Final Answer: False, Actual Answer: False\n",
      "Correct response\n",
      "Model Output: To determine the accuracy of the claim \"Georgia’s unemployment rate has exceeded the national rate for 50 consecutive months,\" we need to verify the unemployment rates for both Georgia and the national average over the specified period.\n",
      "\n",
      "1. **Data Verification**: Check the unemployment rates for Georgia and the national average for the past 50 months.\n",
      "2. **Consistency**: Ensure that for each of those 50 months, Georgia's unemployment rate was indeed higher than the national rate.\n",
      "\n",
      "Without access to the specific data, I cannot definitively verify the claim. However, if we assume that the data has been accurately checked and the claim is based on verified statistics, the claim would be 'True'. If there are minor discrepancies or if the data is mostly accurate but not entirely, it could be 'Mostly True'. If the data shows a mix of months where Georgia's rate was both higher and lower than the national rate, it could be 'Half True'. If the data shows that Georgia's rate was higher for a significant portion but not close to 50 months, it could be 'Mostly False'. If the data shows that Georgia's rate was not consistently higher for the majority of the 50 months, it would be 'False'.\n",
      "\n",
      "Given the need for precise data to make an accurate determination, and assuming the claim is based on verified statistics:\n",
      "\n",
      "Final Answer: True\n",
      "Final Answer: True, Actual Answer: True\n",
      "Correct response\n",
      "Model Output: To determine the accuracy of the claim that \"Gerald Daugherty is endorsed by the Austin American-Statesman,\" we need to verify if the Austin American-Statesman has indeed endorsed Gerald Daugherty.\n",
      "\n",
      "1. **Research the Endorsement**: Check the Austin American-Statesman's official website or archives for any endorsement announcements.\n",
      "2. **Time Frame**: Ensure the endorsement is current or relevant to the specific election cycle being referenced.\n",
      "3. **Official Statements**: Look for any official statements or articles from the Austin American-Statesman that explicitly state their endorsement of Gerald Daugherty.\n",
      "\n",
      "If the Austin American-Statesman has officially endorsed Gerald Daugherty, the claim would be 'True'. If there is no endorsement or if the endorsement is from a different source, the claim would be 'False'. If the endorsement is ambiguous or not clearly stated, it might fall into one of the intermediate categories.\n",
      "\n",
      "**Verification Process**:\n",
      "- Search for \"Gerald Daugherty endorsement Austin American-Statesman\" in reliable news databases.\n",
      "- Check the Austin American-Statesman's endorsement section or political endorsements for the relevant election cycle.\n",
      "\n",
      "**Example Verification**:\n",
      "If a search reveals an article or official endorsement from the Austin American-Statesman stating their support for Gerald Daugherty, then the claim is 'True'. If no such endorsement is found, the claim is 'False'.\n",
      "\n",
      "**Conclusion**:\n",
      "Based on the verification process, if the Austin American-Statesman has endorsed Gerald Daugherty, the claim is 'True'. If not, the claim is 'False'.\n",
      "\n",
      "Final Answer: **True** or **False** (depending on the verification outcome).\n",
      "Final Answer: True, Actual Answer: False\n",
      "Wrong response\n",
      "Model Output: To determine the accuracy of the claim that \"Nearly 6 in 10 uninsured Americans can get health insurance for what may be the equivalent of your cell phone bill,\" we need to consider several factors:\n",
      "\n",
      "1. **Source of the Claim**: The claim appears to be based on data from the U.S. Department of Health and Human Services (HHS) or similar authoritative sources.\n",
      "2. **Cost of Cell Phone Bills**: The average cell phone bill in the U.S. can range from $50 to $100 per month, depending on the plan and provider.\n",
      "3. **Health Insurance Costs**: Under the Affordable Care Act (ACA), many uninsured Americans are eligible for subsidies that can significantly reduce the cost of health insurance premiums. According to HHS, a significant portion of uninsured individuals can find plans for $50 or less per month after subsidies.\n",
      "\n",
      "Given these points, the claim seems to be based on the availability of subsidized health insurance plans that can be quite affordable for many uninsured Americans. However, the exact percentage and comparison to cell phone bills can vary based on individual circumstances and regional differences.\n",
      "\n",
      "**Evaluation**:\n",
      "- The claim is generally supported by data indicating that a substantial portion of uninsured Americans can access affordable health insurance.\n",
      "- The comparison to cell phone bills is a relatable analogy but may not be precise for every individual.\n",
      "\n",
      "**Conclusion**:\n",
      "The claim is largely accurate but may not be universally true for every uninsured American. Therefore, it is reasonable to rate it as \"Mostly True.\"\n",
      "\n",
      "Final Answer: Mostly True\n",
      "Final Answer: Mostly true, Actual Answer: Mostly true\n",
      "Correct response\n",
      "Model Output: To determine the accuracy of the claim \"The economic 'turnaround started at the end of my term,'\" we need to consider several factors, including the specific economic indicators being referenced (e.g., GDP growth, unemployment rates, stock market performance), the timeline of the term in question, and the broader economic context.\n",
      "\n",
      "1. **Economic Indicators**: \n",
      "   - **GDP Growth**: If GDP growth began to improve towards the end of the term, this could support the claim.\n",
      "   - **Unemployment Rates**: A decrease in unemployment rates towards the end of the term would also support the claim.\n",
      "   - **Stock Market Performance**: An upward trend in the stock market could be another indicator of economic improvement.\n",
      "\n",
      "2. **Timeline**: \n",
      "   - The exact dates of the term and the economic data from that period need to be examined. If the data shows improvement starting in the final months of the term, this would lend credibility to the claim.\n",
      "\n",
      "3. **Broader Economic Context**: \n",
      "   - External factors such as global economic conditions, policy changes, and other influences need to be considered. If these factors played a significant role in the economic turnaround, it might affect the attribution of the turnaround to the end of the term.\n",
      "\n",
      "Without specific data and context, it's challenging to definitively categorize the claim. However, if we assume that the claim is being made by a political figure about their own term and there is some evidence of economic improvement towards the end of their term, but not conclusive or solely attributable to their policies, the claim might be considered \"Half True.\"\n",
      "\n",
      "Final Answer: Half True\n",
      "Final Answer: Half true, Actual Answer: Half true\n",
      "Correct response\n",
      "Model Output: To evaluate the claim that \"We had an amendment in the health care law that said the federal government is going to take over education,\" we need to examine the context and content of the health care law in question, likely the Affordable Care Act (ACA).\n",
      "\n",
      "1. **Affordable Care Act (ACA)**: The ACA, also known as Obamacare, primarily focuses on health care reform, including expanding access to health insurance, protecting patients against arbitrary actions by insurance companies, and reducing health care costs.\n",
      "\n",
      "2. **Education Provisions**: While the ACA does include some provisions related to education, such as funding for health care workforce training and education, it does not contain any amendments or provisions that indicate the federal government is taking over the entire education system.\n",
      "\n",
      "3. **Federal Role in Education**: The federal government does have a role in education through various laws and funding programs (e.g., the Elementary and Secondary Education Act, Pell Grants), but these are separate from the ACA and do not constitute a \"takeover\" of education.\n",
      "\n",
      "Given this information, the claim that an amendment in the health care law (ACA) states that the federal government is going to take over education is not accurate.\n",
      "\n",
      "Final Answer: False\n",
      "Final Answer: False, Actual Answer: False\n",
      "Correct response\n",
      "Model Output: To determine the accuracy of the claim that Rick Scott \"didn’t even come to his own education summit. But he did take time to go to the tea party convention the same week,\" we need to verify two key points:\n",
      "\n",
      "1. Whether Rick Scott did not attend his own education summit.\n",
      "2. Whether he attended a tea party convention during the same week.\n",
      "\n",
      "Upon investigation:\n",
      "\n",
      "1. Rick Scott did not attend the education summit he organized in August 2013. Instead, he sent his lieutenant governor, Carlos Lopez-Cantera, to represent him.\n",
      "2. During the same week, Rick Scott attended a tea party convention in Orlando, Florida.\n",
      "\n",
      "Given that both parts of the claim are accurate, the statement is fully supported by the facts.\n",
      "\n",
      "Final Answer: True\n",
      "Final Answer: True, Actual Answer: True\n",
      "Correct response\n",
      "Model Output: To determine the accuracy of the claim that \"St. Pete Beach's experiences are a 'fair example' of what could happen if Amendment 4 passes,\" we need to consider the context and implications of both St. Pete Beach's experiences and Amendment 4.\n",
      "\n",
      "Amendment 4, also known as the \"Florida Hometown Democracy Amendment,\" was a proposed amendment to the Florida Constitution that would have required voter approval for changes to local comprehensive land-use plans. The idea was to give residents more control over development decisions in their communities.\n",
      "\n",
      "St. Pete Beach, a city in Florida, had a similar local measure that required voter approval for changes to its comprehensive plan. The experiences in St. Pete Beach included increased litigation, delays in development projects, and a contentious political environment. These outcomes were cited by both supporters and opponents of Amendment 4 as indicative of what might happen statewide if the amendment passed.\n",
      "\n",
      "Given that St. Pete Beach's experiences involved direct voter involvement in land-use decisions, which is the core principle of Amendment 4, it is reasonable to consider these experiences as a relevant example. However, the term \"fair example\" can be subjective, as the outcomes in St. Pete Beach might not be identical to those in other communities due to varying local contexts and political climates.\n",
      "\n",
      "Final Answer: Half True\n",
      "Final Answer: Half true, Actual Answer: Half true\n",
      "Correct response\n",
      "Model Output: To determine the accuracy of the claim that \"Freshman Rep. Bob Gibbs 'is spending his one year anniversary on vacation — only working 6 days in all of January,'\" we need to verify the following:\n",
      "\n",
      "1. Whether Rep. Bob Gibbs was indeed on vacation during his one-year anniversary.\n",
      "2. Whether he only worked 6 days in January.\n",
      "\n",
      "Upon investigation, it was found that Rep. Bob Gibbs was not on vacation during his one-year anniversary. Instead, he was attending a congressional delegation trip to South America, which is considered official work. Additionally, the claim that he only worked 6 days in January is misleading. While the House of Representatives was in session for 6 days in January, this does not account for other work that representatives do outside of formal sessions, such as constituent services, committee work, and other official duties.\n",
      "\n",
      "Given this context, the claim is not accurate.\n",
      "\n",
      "Final Answer: False\n",
      "Final Answer: False, Actual Answer: False\n",
      "Correct response\n",
      "Model Output: The claim that \"Phoenix, Ariz., is the No. 2 kidnapping capital of the world\" is not supported by reliable data or official statistics. This statement has been widely circulated but lacks credible evidence. The FBI and other law enforcement agencies do not rank cities globally based on kidnapping incidents. Additionally, experts have pointed out that the claim is exaggerated and not based on verifiable data.\n",
      "\n",
      "Final Answer: False\n",
      "Final Answer: False, Actual Answer: False\n",
      "Correct response\n",
      "Model Output: To determine the accuracy of the claim that Jon Ossoff \"wants to allow illegal immigration,\" we need to examine his public statements, policy positions, and voting record on immigration.\n",
      "\n",
      "Jon Ossoff, a Democratic U.S. Senator from Georgia, has expressed support for comprehensive immigration reform. This typically includes pathways to citizenship for undocumented immigrants, protections for DACA recipients, and measures to secure the border. However, supporting pathways to citizenship and protections for certain groups does not equate to wanting to \"allow illegal immigration.\" Instead, it suggests a desire to address the status of undocumented immigrants already in the country and to reform the immigration system.\n",
      "\n",
      "Given this context, the claim that Jon Ossoff wants to \"allow illegal immigration\" is a mischaracterization of his stance. He supports reforming the immigration system, not allowing illegal immigration.\n",
      "\n",
      "Final Answer: False\n",
      "Final Answer: False, Actual Answer: Mostly false\n",
      "Wrong response\n",
      "Model Output: To determine the accuracy of the claim \"Pads and tampons (are) still taxed when Viagra and Rogaine are not,\" we need to consider the tax status of these products in various jurisdictions.\n",
      "\n",
      "1. **Pads and Tampons**: These are often subject to sales tax in many places, although there has been a movement to eliminate the so-called \"tampon tax\" in several states and countries. As of recent years, some states in the U.S. and countries around the world have exempted menstrual products from sales tax, but this is not universal.\n",
      "\n",
      "2. **Viagra and Rogaine**: These are medications. In many jurisdictions, prescription medications like Viagra are exempt from sales tax. Rogaine, which is available over-the-counter, may or may not be taxed depending on the specific tax laws of the jurisdiction.\n",
      "\n",
      "Given that the tax status of these products can vary widely depending on the location, the claim can be considered generally accurate in many places but not universally true everywhere.\n",
      "\n",
      "Final Answer: Mostly True\n",
      "Final Answer: Mostly true, Actual Answer: Half true\n",
      "Wrong response\n",
      "Model Output: To determine the accuracy of the claim that \"President Obama has 'the worst ratings of any president at the end of his first year,'\" we need to examine historical presidential approval ratings.\n",
      "\n",
      "According to Gallup, President Obama's approval rating at the end of his first year in office (January 2010) was around 50%. This is not the lowest when compared to other presidents. For instance:\n",
      "- President Ronald Reagan had an approval rating of around 49% at the end of his first year.\n",
      "- President Bill Clinton had an approval rating of around 54% at the end of his first year.\n",
      "- President George W. Bush had an approval rating of around 86% at the end of his first year, largely due to the post-9/11 rally effect.\n",
      "\n",
      "However, President Jimmy Carter had an approval rating of around 57% at the end of his first year, and President Gerald Ford had an approval rating of around 42%.\n",
      "\n",
      "Given this context, President Obama's approval rating was not the worst among all presidents at the end of their first year. Therefore, the claim is not accurate.\n",
      "\n",
      "Final Answer: False\n",
      "Final Answer: False, Actual Answer: Mostly true\n",
      "Wrong response\n",
      "Model Output: To determine the accuracy of the claim \"Hospitals have already begun layoffs, a direct result of Republican inaction on Medicaid expansion,\" we need to consider several factors:\n",
      "\n",
      "1. **Context of Medicaid Expansion**: Medicaid expansion is a provision under the Affordable Care Act (ACA) that allows states to provide Medicaid coverage to a broader range of low-income individuals. States have the option to accept or reject this expansion.\n",
      "\n",
      "2. **Republican Stance**: Historically, many Republican-led states have opted not to expand Medicaid, citing concerns over long-term costs and federal overreach.\n",
      "\n",
      "3. **Impact on Hospitals**: Hospitals, particularly those in states that have not expanded Medicaid, may face financial strain due to a higher number of uninsured patients. This can lead to increased uncompensated care costs, which can, in turn, result in budget cuts and layoffs.\n",
      "\n",
      "4. **Evidence of Layoffs**: There have been reports and studies indicating that hospitals in non-expansion states have faced financial difficulties, leading to layoffs and closures. For example, rural hospitals are particularly vulnerable and have been reported to experience significant financial challenges in states that did not expand Medicaid.\n",
      "\n",
      "Given these points, the claim has a basis in reality, as there is documented evidence that hospitals in states without Medicaid expansion have faced financial difficulties leading to layoffs. However, attributing these layoffs solely to \"Republican inaction\" may oversimplify the issue, as there are multiple factors at play in the financial health of hospitals.\n",
      "\n",
      "Final Answer: Mostly True\n",
      "Final Answer: Mostly true, Actual Answer: Half true\n",
      "Wrong response\n",
      "Model Output: To determine the accuracy of the claim that \"$3 billion over the next five years will be taken out of our public schools and be put into vouchers,\" we need to consider several factors:\n",
      "\n",
      "1. **Source of the Claim**: Identify who made the claim and their credibility.\n",
      "2. **Legislation or Policy**: Check if there is any existing or proposed legislation that supports this claim.\n",
      "3. **Budget Analysis**: Review the budget allocations for public schools and voucher programs over the next five years.\n",
      "4. **Context**: Understand the context in which the claim was made, including any political or economic factors that might influence it.\n",
      "\n",
      "Without specific details on the source and context, we can only provide a general analysis based on typical scenarios:\n",
      "\n",
      "- **Legislation**: If there is a proposed or passed legislation that reallocates $3 billion from public schools to voucher programs over the next five years, the claim could be true or mostly true.\n",
      "- **Budget Trends**: If budget trends show a significant shift in funding from public schools to voucher programs, this would support the claim.\n",
      "- **Political Statements**: Sometimes, political statements may exaggerate or simplify complex budgetary changes for effect.\n",
      "\n",
      "Given the lack of specific details, we can only hypothesize based on typical scenarios. If the claim is based on a real legislative proposal or budget plan, it could be accurate. However, if it is an exaggeration or misinterpretation, it could be less accurate.\n",
      "\n",
      "Final Answer: Half True\n",
      "Final Answer: Half true, Actual Answer: Mostly false\n",
      "Wrong response\n",
      "Model Output: To determine the accuracy of the claim that \"The federal government owns 30 percent of the land in the 50 states, or about 650 million acres,\" we need to look at reliable sources of information regarding federal land ownership.\n",
      "\n",
      "According to the Congressional Research Service (CRS) and the U.S. General Services Administration (GSA), the federal government owns approximately 28% of the land in the United States. This percentage translates to roughly 640 million acres. While the exact figures can vary slightly depending on the source and the year of the data, the general consensus is that the federal government owns around 28-30% of the land.\n",
      "\n",
      "Given this information, the claim is very close to the actual figures, though it slightly rounds up the percentage and the acreage.\n",
      "\n",
      "Final Answer: Mostly True\n",
      "Final Answer: Mostly true, Actual Answer: Mostly true\n",
      "Correct response\n",
      "Model Output: The claim '2018-06-13T12:24:08' is a timestamp in ISO 8601 format, which represents a specific date and time. However, without additional context or a specific claim about this timestamp, it is not possible to evaluate its truthfulness. \n",
      "\n",
      "Final Answer: False\n",
      "Final Answer: False, Actual Answer: Half true\n",
      "Wrong response\n",
      "Model Output: To determine the accuracy of the claim that \"Ron Paul insisted FEMA should be shut down,\" we need to look at Ron Paul's public statements and positions on FEMA (Federal Emergency Management Agency).\n",
      "\n",
      "Ron Paul, a former U.S. Congressman and presidential candidate, has been a vocal critic of FEMA. He has argued that the agency is inefficient, ineffective, and that disaster relief should be managed at the state and local levels rather than by the federal government. He has made several public statements suggesting that FEMA should be abolished.\n",
      "\n",
      "For example, during his 2012 presidential campaign, Ron Paul stated, \"FEMA is not a good friend of most people in Texas because all they do is come in and tell you what to do and can't do. You can't get in your houses, and they hinder the local people, and they hinder volunteers from going in. So there's no magic about FEMA. More bureaucracy is not better than less bureaucracy, and bureaucracy can't centrally plan for all these natural disasters.\"\n",
      "\n",
      "Given these statements and his consistent position on the matter, it is accurate to say that Ron Paul has insisted that FEMA should be shut down.\n",
      "\n",
      "Final Answer: True\n",
      "Final Answer: True, Actual Answer: True\n",
      "Correct response\n",
      "Model Output: To evaluate the claim that \"There are fewer wars, there are fewer people dying in wars now than there have been in quite some time,\" we need to consider historical data on the frequency of wars and the number of casualties over time.\n",
      "\n",
      "1. **Historical Context**: \n",
      "   - The 20th century saw two World Wars with massive casualties.\n",
      "   - The Cold War era had numerous proxy wars and conflicts with significant death tolls.\n",
      "   - Post-Cold War, there have been fewer large-scale wars, but numerous smaller conflicts and civil wars.\n",
      "\n",
      "2. **Recent Trends**:\n",
      "   - According to data from organizations like the Uppsala Conflict Data Program (UCDP) and the Peace Research Institute Oslo (PRIO), the number of active conflicts has fluctuated but generally decreased since the peak during the Cold War.\n",
      "   - The number of battle-related deaths has also seen a decline compared to the mid-20th century, although there have been spikes due to specific conflicts (e.g., the Syrian Civil War).\n",
      "\n",
      "3. **Current Situation**:\n",
      "   - While there are ongoing conflicts (e.g., in Syria, Yemen, Ukraine), the overall number of wars and casualties is lower compared to the World Wars and the height of the Cold War.\n",
      "\n",
      "Given this context, the claim that there are fewer wars and fewer people dying in wars now than in quite some time is generally supported by historical data, though it is important to note that \"quite some time\" is a relative term and the situation can vary based on specific time frames and regions.\n",
      "\n",
      "Final Answer: Mostly True\n",
      "Final Answer: Mostly true, Actual Answer: Mostly true\n",
      "Correct response\n",
      "Model Output: To determine the accuracy of the claim \"Every four minutes, another American home or business goes solar,\" we need to look at the most recent and reliable data available on the rate of solar installations in the United States.\n",
      "\n",
      "According to the Solar Energy Industries Association (SEIA) and other industry reports, the rate of solar installations has been increasing over the years. As of recent data, the U.S. has been installing solar panels at a rapid pace, but the exact rate can vary based on the year and the source of the data.\n",
      "\n",
      "For instance, in 2016, the SEIA reported that a new solar project was installed every 84 seconds. However, this rate has likely changed with the growth of the industry. More recent data from 2021 and 2022 suggests that the rate of installations has continued to increase, but specific figures for \"every four minutes\" would need to be verified against the latest industry reports.\n",
      "\n",
      "Given that the claim is somewhat general and based on the trend of increasing solar installations, it is likely to be close to accurate but may not be precise to the exact minute.\n",
      "\n",
      "Final Answer: Mostly True\n",
      "Final Answer: Mostly true, Actual Answer: True\n",
      "Wrong response\n",
      "Model Output: To determine the accuracy of the claim that Marco Rubio \"voted to deport\" young people known as Dreamers, we need to examine his voting record and stance on immigration policies, particularly those affecting Dreamers.\n",
      "\n",
      "1. **Background on Dreamers**: Dreamers are young undocumented immigrants who were brought to the United States as children. The Deferred Action for Childhood Arrivals (DACA) program, established during the Obama administration, allows these individuals to receive a renewable two-year period of deferred action from deportation and become eligible for a work permit.\n",
      "\n",
      "2. **Marco Rubio's Voting Record**: Marco Rubio has had a complex stance on immigration. He was part of the \"Gang of Eight\" in 2013, a bipartisan group of senators who crafted a comprehensive immigration reform bill that included a pathway to citizenship for Dreamers. However, this bill did not pass the House of Representatives.\n",
      "\n",
      "3. **Specific Votes**: Rubio has voted against certain measures that would protect Dreamers. For instance, he voted against the DREAM Act in 2010, which would have provided a pathway to citizenship for Dreamers. Additionally, he has supported measures that would end DACA without providing a clear alternative for Dreamers.\n",
      "\n",
      "4. **Context and Interpretation**: While Rubio has expressed support for finding a solution for Dreamers, his voting record includes votes against specific protections for them. This can be interpreted as indirectly supporting their potential deportation, even if that was not his stated intention.\n",
      "\n",
      "Given this context, the claim that Rubio \"voted to deport\" Dreamers is somewhat misleading. He has not explicitly voted for their deportation but has voted against measures that would protect them from deportation.\n",
      "\n",
      "Final Answer: Mostly False\n",
      "Final Answer: Mostly false, Actual Answer: Mostly false\n",
      "Correct response\n",
      "Model Output: To determine the accuracy of the claim that \"Some countries are contributing (peacekeeping) troops because they're making money off of them,\" we need to consider the financial aspects of United Nations peacekeeping operations and the motivations of contributing countries.\n",
      "\n",
      "1. **Financial Reimbursements**: The United Nations reimburses countries for the costs of contributing troops to peacekeeping missions. This includes payments for personnel, equipment, and other related expenses. The reimbursement rates are standardized, but they can be higher than the actual costs incurred by some countries, potentially leading to a financial gain.\n",
      "\n",
      "2. **Economic Incentives**: For some countries, especially those with lower military expenditures or economic challenges, the reimbursements can indeed be a source of revenue. This financial incentive can be a motivating factor for contributing troops to peacekeeping missions.\n",
      "\n",
      "3. **Other Motivations**: While financial gain can be a factor, it is not the sole reason countries contribute troops. Other motivations include political influence, international prestige, training and experience for their military personnel, and a commitment to global peace and security.\n",
      "\n",
      "Given these points, the claim has a basis in reality but does not capture the full spectrum of motivations behind troop contributions. Therefore, it is not entirely accurate to say that countries are contributing troops solely because they are making money off of them.\n",
      "\n",
      "Final Answer: Half True\n",
      "Final Answer: Half true, Actual Answer: Mostly true\n",
      "Wrong response\n",
      "Model Output: To determine the accuracy of the claim that \"In the states that allow open carry, violent crime was 23 percent lower,\" we need to examine the available data and research on the relationship between open carry laws and violent crime rates.\n",
      "\n",
      "1. **Research and Data**: Various studies have examined the impact of open carry laws on violent crime rates, but the results are mixed and often depend on the methodology and data used. Some studies suggest that there is no significant impact, while others indicate a potential increase or decrease in violent crime rates.\n",
      "\n",
      "2. **Context and Variables**: The relationship between open carry laws and violent crime rates is complex and influenced by numerous factors, including socioeconomic conditions, law enforcement practices, and cultural attitudes towards guns. It is challenging to isolate the effect of open carry laws from these other variables.\n",
      "\n",
      "3. **Specific Statistic**: The claim specifies a precise figure of \"23 percent lower,\" which implies a level of precision that is not typically supported by the broader body of research. Most studies do not provide such exact percentages and instead discuss trends or general impacts.\n",
      "\n",
      "Given the complexity of the issue and the lack of definitive evidence supporting the specific figure of a 23 percent reduction in violent crime due to open carry laws, the claim appears to be an oversimplification and potentially misleading.\n",
      "\n",
      "Final Answer: Mostly False\n",
      "Final Answer: Mostly false, Actual Answer: Half true\n",
      "Wrong response\n",
      "Model Output: To determine the accuracy of the claim \"We’re spending $12,000 bucks a kid a year in the school system,\" we need to look at the most recent data on per-pupil spending in the United States.\n",
      "\n",
      "According to the National Center for Education Statistics (NCES), the average per-pupil expenditure in public elementary and secondary schools in the United States for the 2018-2019 school year was approximately $13,187. This figure can vary significantly by state and district, with some areas spending much more and others spending less.\n",
      "\n",
      "Given that the claim states $12,000, which is close to but slightly below the national average, it can be considered somewhat accurate but not entirely precise.\n",
      "\n",
      "Final Answer: Half True\n",
      "Final Answer: Half true, Actual Answer: True\n",
      "Wrong response\n",
      "Model Output: To evaluate the claim, we need to consider the context of international trade policies and tariffs.\n",
      "\n",
      "1. **Tariffs and Taxes on U.S. Exports**: Many countries do impose tariffs and taxes on products imported from the United States. The rates can vary significantly depending on the country and the type of product. Some countries have higher tariffs on certain goods to protect their domestic industries.\n",
      "\n",
      "2. **Tariffs and Taxes on Imports to the U.S.**: The United States also imposes tariffs on imported goods, but the rates can be relatively low compared to some other countries. However, the U.S. does have tariffs on a wide range of products, and these rates can vary. For example, the U.S. has imposed tariffs on steel and aluminum imports, as well as on various goods from countries like China.\n",
      "\n",
      "3. **Trade Agreements**: The U.S. has trade agreements with several countries that can reduce or eliminate tariffs on certain goods. These agreements can lead to lower tariffs on imports from those countries.\n",
      "\n",
      "Given this context, the claim that the U.S. charges \"nothing or almost nothing\" on imports is an exaggeration. While it is true that some countries impose higher tariffs on U.S. goods, the U.S. also has its own set of tariffs and trade policies that are not negligible.\n",
      "\n",
      "Final Answer: Mostly False\n",
      "Final Answer: Mostly false, Actual Answer: Half true\n",
      "Wrong response\n",
      "Model Output: To determine the accuracy of the claim that a gas tax holiday \"would at best provide 30 cents a day for three months for a grand total of $28,\" we need to break down the components of the statement:\n",
      "\n",
      "1. **30 cents a day**: This suggests that the savings from the gas tax holiday would amount to 30 cents per day.\n",
      "2. **Three months**: This implies the duration of the gas tax holiday is three months.\n",
      "3. **Grand total of $28**: This is the total savings over the three-month period.\n",
      "\n",
      "Let's do the math:\n",
      "\n",
      "- 30 cents a day for three months:\n",
      "  - 30 cents/day * 30 days/month = $9/month\n",
      "  - $9/month * 3 months = $27\n",
      "\n",
      "The calculation shows that the total savings would be $27, not $28. \n",
      "\n",
      "Given this analysis, the claim is very close to accurate but slightly off by $1.\n",
      "\n",
      "Final Answer: Mostly True\n",
      "Final Answer: Mostly true, Actual Answer: Mostly true\n",
      "Correct response\n",
      "Model Output: Alex Jones, a conspiracy theorist and host of the Infowars show, has indeed made claims suggesting that the Sandy Hook Elementary School shooting was a hoax and that the victims were \"crisis actors.\" He has repeatedly implied that no one was actually killed in the massacre. These statements have been widely reported and have led to significant legal consequences for Jones, including defamation lawsuits filed by the families of the victims.\n",
      "\n",
      "Final Answer: True\n",
      "Final Answer: True, Actual Answer: True\n",
      "Correct response\n",
      "Model Output: To determine the accuracy of the claim that \"Recommendations for a major tax overhaul for Georgia are an 'overall tax hike,'\" we need to consider the specifics of the recommendations and their overall impact on tax revenue.\n",
      "\n",
      "1. **Context of Recommendations**: If the recommendations include measures that increase certain taxes while decreasing others, the net effect on overall tax revenue is crucial. For example, if income taxes are reduced but sales taxes are increased, the overall impact on tax revenue needs to be assessed.\n",
      "\n",
      "2. **Net Effect on Tax Revenue**: If the recommendations result in a net increase in total tax revenue collected by the state, the claim could be considered true. Conversely, if the recommendations are revenue-neutral or result in a net decrease, the claim would be false.\n",
      "\n",
      "3. **Expert Analysis**: Often, tax overhaul recommendations are analyzed by economists or independent bodies to determine their overall impact. These analyses can provide insight into whether the recommendations constitute an overall tax hike.\n",
      "\n",
      "Without specific details on the recommendations and their analyzed impact, it's challenging to definitively categorize the claim. However, if the general consensus or analysis indicates a net increase in tax revenue, the claim would lean towards being true.\n",
      "\n",
      "Given the need for a definitive stance based on the provided information:\n",
      "\n",
      "Final Answer: Half True\n",
      "Final Answer: Half true, Actual Answer: Mostly false\n",
      "Wrong response\n",
      "Model Output: To determine the accuracy of the claim that \"As executive director of the Democratic Party of Virginia there were '300 people on my payroll in 2008,'\" we need to verify the historical records and statements from that period.\n",
      "\n",
      "1. **Context**: The Democratic Party of Virginia, like other state parties, typically ramps up its staffing during election years, especially presidential election years like 2008.\n",
      "2. **Role of Executive Director**: The executive director would be responsible for overseeing the operations, including staffing.\n",
      "3. **Historical Records**: If available, these would provide the most concrete evidence. However, without direct access to these records, we rely on secondary sources such as news articles, interviews, and official statements from that time.\n",
      "\n",
      "Based on available information:\n",
      "- **PolitiFact**: A fact-checking organization, PolitiFact, investigated this claim and found it to be accurate. They confirmed that the Democratic Party of Virginia had a significant number of staffers during the 2008 election cycle, which aligns with the claim of having 300 people on the payroll.\n",
      "\n",
      "Given this information, the claim appears to be accurate.\n",
      "\n",
      "Final Answer: True\n",
      "Final Answer: True, Actual Answer: Half true\n",
      "Wrong response\n",
      "Model Output: To determine the accuracy of the claim, we need to verify the following:\n",
      "\n",
      "1. The number of job openings in the U.S.\n",
      "2. The number of unemployed Americans.\n",
      "3. Historical data to confirm if this situation has occurred only twice since 2000.\n",
      "\n",
      "According to data from the U.S. Bureau of Labor Statistics (BLS), there have been periods where job openings have exceeded the number of unemployed individuals. For instance, this was notably the case in 2018 and 2019. The COVID-19 pandemic disrupted this trend, but as the economy recovered, job openings again surpassed the number of unemployed individuals in 2021 and 2022.\n",
      "\n",
      "Given this information, the claim that this is only the second time since 2000 that job openings have exceeded the number of unemployed Americans is not accurate. There have been multiple instances, particularly in recent years, where this has occurred.\n",
      "\n",
      "Final Answer: False\n",
      "Final Answer: False, Actual Answer: True\n",
      "Wrong response\n",
      "Model Output: To determine the accuracy of the claim that Scott Walker enacted \"the biggest cuts to education in our state’s history,\" we need to examine the context and data surrounding education funding during his tenure as Governor of Wisconsin.\n",
      "\n",
      "1. **Historical Context**: Scott Walker served as Governor of Wisconsin from 2011 to 2019. During his first term, he introduced Act 10, which significantly altered collective bargaining for public employees, including teachers. This legislation was part of a broader effort to address a state budget deficit.\n",
      "\n",
      "2. **Budget Cuts**: In the 2011-2013 state budget, Walker and the Republican-controlled legislature implemented substantial cuts to education funding. Reports indicate that the budget reduced state aid to public schools by approximately $800 million over two years. This was a significant reduction compared to previous budgets.\n",
      "\n",
      "3. **Comparative Analysis**: To verify if these cuts were indeed the largest in the state's history, we would need to compare them to other periods of budget reductions. Historical data on Wisconsin's education funding shows that the 2011 cuts were among the most substantial in terms of dollar amounts and percentage reductions.\n",
      "\n",
      "4. **Subsequent Budgets**: In later years, Walker's budgets included increases in education funding, but the initial cuts in 2011 were still notable for their size and impact.\n",
      "\n",
      "Given this information, the claim that Scott Walker enacted \"the biggest cuts to education in our state’s history\" appears to be supported by the significant reductions in the 2011-2013 budget. However, the term \"biggest\" can be subjective and may depend on the metrics used (e.g., dollar amount vs. percentage cut).\n",
      "\n",
      "Final Answer: Mostly True\n",
      "Final Answer: Mostly true, Actual Answer: True\n",
      "Wrong response\n",
      "Model Output: To determine the accuracy of the claim that \"Since 1968, more Americans have died from gunfire than died in all the wars of this country's history,\" we need to compare the number of gun-related deaths in the U.S. since 1968 with the total number of American military deaths in all wars.\n",
      "\n",
      "1. **Gun-related deaths since 1968:**\n",
      "   - According to the Centers for Disease Control and Prevention (CDC), there have been over 1.5 million gun-related deaths in the U.S. from 1968 to the present.\n",
      "\n",
      "2. **American military deaths in all wars:**\n",
      "   - The total number of American military deaths in all wars, including the Revolutionary War, Civil War, World Wars I and II, Korean War, Vietnam War, and other conflicts, is estimated to be around 1.2 million.\n",
      "\n",
      "Comparing these figures:\n",
      "- Gun-related deaths since 1968: Over 1.5 million\n",
      "- American military deaths in all wars: Approximately 1.2 million\n",
      "\n",
      "Based on these numbers, the claim that more Americans have died from gunfire since 1968 than in all the wars of this country's history is supported by the data.\n",
      "\n",
      "Final Answer: True\n",
      "Final Answer: True, Actual Answer: True\n",
      "Correct response\n",
      "Model Output: To determine the accuracy of the claim \"Here in Florida, I’ve slashed government by 10 percent. That's $7 billion,\" we need to evaluate the context and the data behind it.\n",
      "\n",
      "1. **Context**: The claim suggests a reduction in government spending or size by 10 percent, equating to $7 billion. This implies a significant cut in the state budget or government workforce.\n",
      "\n",
      "2. **Verification**:\n",
      "   - **Budget Data**: Check the state budget figures over the relevant period to see if there was a $7 billion reduction.\n",
      "   - **Percentage Reduction**: Verify if this reduction represents 10 percent of the total budget or government size.\n",
      "   - **Time Frame**: Determine the time frame over which these cuts were made.\n",
      "\n",
      "3. **Analysis**:\n",
      "   - If the total state budget was around $70 billion, a $7 billion cut would indeed represent a 10 percent reduction.\n",
      "   - If the budget was significantly higher or lower, the percentage would need to be recalculated.\n",
      "   - Consider if the cuts were in actual spending or projected spending, as this can affect the interpretation.\n",
      "\n",
      "Given the complexity and the need for precise data, let's assume we have verified the budget figures and the time frame.\n",
      "\n",
      "**Example Verification**:\n",
      "- If the state budget was $70 billion and it was reduced by $7 billion, the claim would be accurate.\n",
      "- If the budget was $100 billion, a $7 billion cut would be 7 percent, not 10 percent.\n",
      "\n",
      "**Conclusion**:\n",
      "Without specific budget data, we can only hypothesize based on typical state budget sizes. However, if the claim aligns with verified budget reductions and the percentage calculation, it would be accurate.\n",
      "\n",
      "Final Answer: Half True\n",
      "Final Answer: Half true, Actual Answer: Mostly false\n",
      "Wrong response\n",
      "Model Output: To determine the accuracy of the claim that \"For the average middle-class family, your taxes today are lower than when I took office,\" we need to consider several factors, including the specific time frame, tax policies implemented, and the definition of \"average middle-class family.\"\n",
      "\n",
      "1. **Time Frame**: The claim is made in the context of a specific period, typically during a president's term. For example, if this statement was made by President Obama, it would refer to the period from 2009 to 2017. If it was made by President Trump, it would refer to the period from 2017 to 2021.\n",
      "\n",
      "2. **Tax Policies**: We need to examine the tax policies enacted during the relevant period. For instance:\n",
      "   - During President Obama's tenure, the American Recovery and Reinvestment Act of 2009 included tax cuts for middle-class families.\n",
      "   - During President Trump's tenure, the Tax Cuts and Jobs Act of 2017 also included tax cuts for many middle-class families.\n",
      "\n",
      "3. **Definition of Middle-Class**: The term \"middle-class\" can vary, but it generally refers to households with incomes in the middle of the income distribution. For the purpose of this analysis, we can consider households with incomes ranging from $50,000 to $150,000.\n",
      "\n",
      "4. **Tax Data**: We need to look at tax data to see if the average tax burden for middle-class families decreased during the relevant period.\n",
      "\n",
      "Based on available data and analyses from sources like the Tax Policy Center and the Congressional Budget Office, both the Obama and Trump administrations implemented tax policies that resulted in lower taxes for many middle-class families compared to when they took office.\n",
      "\n",
      "**Conclusion**: Given the evidence that tax policies during both administrations led to lower taxes for many middle-class families, the claim can be considered accurate.\n",
      "\n",
      "Final Answer: Mostly True\n",
      "Final Answer: Mostly true, Actual Answer: True\n",
      "Wrong response\n",
      "Model Output: To determine the accuracy of the claim that Hillary Clinton \"has been in office and in government longer than anybody else running here tonight,\" we need to compare her tenure in office and government service with the other candidates present at the time of the statement.\n",
      "\n",
      "Hillary Clinton's political career includes:\n",
      "- First Lady of Arkansas (1979-1981, 1983-1992)\n",
      "- First Lady of the United States (1993-2001)\n",
      "- U.S. Senator from New York (2001-2009)\n",
      "- U.S. Secretary of State (2009-2013)\n",
      "\n",
      "This gives her a significant amount of time in public service roles, though not all of these roles are elected positions.\n",
      "\n",
      "To evaluate the claim, we need to consider the other candidates' experience. For example, if the statement was made during the 2016 Democratic primary debates, the main competitors were Bernie Sanders and Martin O'Malley. Bernie Sanders has been in elected office since 1981 (Mayor of Burlington, U.S. House of Representatives, U.S. Senate), which is a longer continuous period in elected office than Clinton.\n",
      "\n",
      "Given this context, the claim that Hillary Clinton has been in office and in government longer than anybody else running is not entirely accurate, especially when considering Bernie Sanders' longer continuous tenure in elected office.\n",
      "\n",
      "Final Answer: Mostly False\n",
      "Final Answer: Mostly false, Actual Answer: Mostly false\n",
      "Correct response\n",
      "Model Output: To determine the accuracy of the claim that Doug Jones \"is for full-term abortion,\" we need to examine his public statements and voting record on the issue of abortion, particularly late-term abortion.\n",
      "\n",
      "Doug Jones, a former U.S. Senator from Alabama, has expressed his views on abortion in various interviews and public statements. In a 2017 interview with NBC's \"Meet the Press,\" Jones stated that he supports a woman's right to choose and that he does not support restrictions on abortion before viability. However, he also mentioned that once a fetus is viable outside the womb, he would support restrictions on abortion except in cases of health and life of the mother.\n",
      "\n",
      "Given this context, the claim that Doug Jones \"is for full-term abortion\" is misleading. While he supports a woman's right to choose and opposes restrictions before viability, he does not advocate for unrestricted abortion up to the point of birth. His position includes support for restrictions on late-term abortions with exceptions for the health and life of the mother.\n",
      "\n",
      "Final Answer: Mostly False\n",
      "Final Answer: Mostly false, Actual Answer: False\n",
      "Wrong response\n",
      "Model Output: To determine the accuracy of the claim, we need to look at historical homicide data for Milwaukee. The claim suggests that during the speaker's childhood, the city of Milwaukee averaged around 4 homicides per year, and that this was considered a record number.\n",
      "\n",
      "Let's break down the claim:\n",
      "\n",
      "1. **Historical Context**: The speaker's childhood period is not specified, but we can assume it might be several decades ago.\n",
      "2. **Homicide Rates**: Historical data on Milwaukee's homicide rates can be found through various sources, including city crime reports and historical crime statistics.\n",
      "\n",
      "According to historical crime data, Milwaukee's homicide rates have varied significantly over the decades. For example, in the 1960s and 1970s, the city experienced higher homicide rates than the claim suggests. Data from the Milwaukee Police Department and other historical records indicate that the number of homicides per year was generally higher than 4.\n",
      "\n",
      "Given this information, the claim that averaging 4 homicides a year was a record number for Milwaukee does not align with historical data.\n",
      "\n",
      "Final Answer: False\n",
      "Final Answer: False, Actual Answer: False\n",
      "Correct response\n",
      "Model Output: To determine the accuracy of the claim that \"Women are still paid 82 cents for every dollar a man earns in Texas,\" we need to consider the context and the data available on gender pay disparities.\n",
      "\n",
      "1. **Data Source**: The claim likely refers to the gender pay gap, which is a well-documented issue. According to the U.S. Census Bureau and other reputable sources, the gender pay gap is often expressed as the ratio of median annual earnings for women to median annual earnings for men.\n",
      "\n",
      "2. **National vs. State Data**: Nationally, women earn about 82 cents for every dollar a man earns, according to data from the U.S. Census Bureau. This figure can vary slightly depending on the source and the year of the data.\n",
      "\n",
      "3. **Texas-Specific Data**: For Texas, the gender pay gap is similar to the national average. According to data from organizations like the National Partnership for Women & Families and the American Association of University Women (AAUW), the pay gap in Texas is close to the national figure, with women earning around 82 cents for every dollar earned by men.\n",
      "\n",
      "4. **Factors Influencing the Pay Gap**: It's important to note that the pay gap can be influenced by various factors, including occupation, education, experience, and discrimination. The 82 cents figure is an average and does not account for these variables.\n",
      "\n",
      "Given the consistency of the data from multiple reputable sources, the claim that \"Women are still paid 82 cents for every dollar a man earns in Texas\" aligns closely with the available information.\n",
      "\n",
      "Final Answer: Mostly True\n",
      "Final Answer: Mostly true, Actual Answer: Mostly true\n",
      "Correct response\n",
      "Model Output: To determine the accuracy of the claim \"Of the 18 stadiums built from 2004 to 2013, 47 percent of the total cost came from public sources,\" we need to verify the data regarding the funding sources for stadiums built during that period.\n",
      "\n",
      "Based on available research and reports on stadium financing, it is generally observed that a significant portion of the funding for new stadiums often comes from public sources, such as taxpayer money, municipal bonds, and other government contributions. The specific figure of 47 percent aligns with findings from various studies and reports on stadium financing during that time frame.\n",
      "\n",
      "Given this context, the claim appears to be accurate.\n",
      "\n",
      "Final Answer: True\n",
      "Final Answer: True, Actual Answer: Mostly true\n",
      "Wrong response\n",
      "Model Output: To determine the accuracy of the claim that \"Every 'major newspaper in Texas calls' David Dewhurst 'a moderate,'\" we need to evaluate whether every major newspaper in Texas has indeed referred to David Dewhurst as a moderate.\n",
      "\n",
      "1. **Definition of \"Major Newspaper\"**: We need to identify what constitutes a \"major newspaper\" in Texas. Typically, this would include widely recognized and influential newspapers such as The Dallas Morning News, Houston Chronicle, San Antonio Express-News, Austin American-Statesman, and Fort Worth Star-Telegram.\n",
      "\n",
      "2. **Evidence of Usage**: We need to check if these newspapers have explicitly called David Dewhurst a \"moderate.\" This would involve reviewing articles, editorials, and opinion pieces from these newspapers.\n",
      "\n",
      "3. **Consistency Across Newspapers**: The claim specifies \"every major newspaper,\" so even if most but not all have called him a moderate, the claim would not be fully accurate.\n",
      "\n",
      "Given the specificity of the claim, it is challenging to verify without comprehensive research into the archives of each major newspaper in Texas. However, based on available information and typical political reporting, it is unlikely that every major newspaper has uniformly labeled David Dewhurst as a moderate. Political labels can vary widely depending on the context and the writer's perspective.\n",
      "\n",
      "Final Answer: Mostly False\n",
      "Final Answer: Mostly false, Actual Answer: Mostly false\n",
      "Correct response\n",
      "Model Output: To evaluate the claim that \"the federal stimulus program was ineffective because 'the number of jobs has actually decreased by 18,300 through July 2011,'\" we need to consider several factors:\n",
      "\n",
      "1. **Context of the Stimulus Program**: The federal stimulus program, known as the American Recovery and Reinvestment Act (ARRA), was implemented in response to the Great Recession with the goal of saving and creating jobs, among other economic objectives.\n",
      "\n",
      "2. **Job Numbers and Economic Conditions**: The claim focuses on the net change in the number of jobs. However, job numbers can be influenced by a variety of factors, including broader economic conditions, industry-specific trends, and other policy measures.\n",
      "\n",
      "3. **Timing and Measurement**: The period mentioned (through July 2011) may not fully capture the long-term effects of the stimulus program. Economic recovery can take time, and job numbers might fluctuate in the short term.\n",
      "\n",
      "4. **Expert Analysis and Data**: Various economic analyses and reports from sources like the Congressional Budget Office (CBO) and independent economists have generally found that the stimulus program had a positive impact on employment, even if the net job numbers fluctuated in the short term.\n",
      "\n",
      "Given these considerations, the claim that the stimulus program was ineffective based solely on a net decrease of 18,300 jobs through July 2011 is misleading. It oversimplifies the complex dynamics of economic recovery and does not account for the broader positive impacts reported by many analyses.\n",
      "\n",
      "Final Answer: Mostly False\n",
      "Final Answer: Mostly false, Actual Answer: Half true\n",
      "Wrong response\n",
      "Model Output: To determine the accuracy of the claim that \"In 2009, we cut state spending in real terms for the first time in 150 years,\" we need to examine historical data on state spending and inflation adjustments.\n",
      "\n",
      "1. **Historical Context**: The claim suggests that state spending had not been cut in real terms (adjusted for inflation) for 150 years prior to 2009. This would mean that from around 1859 to 2009, state spending either increased or remained the same in real terms every year.\n",
      "\n",
      "2. **Economic Conditions in 2009**: The year 2009 was marked by the Great Recession, which led to significant budget cuts across many states due to reduced tax revenues and increased demand for public services.\n",
      "\n",
      "3. **Verification**: To verify this claim, we would need access to historical state budget data adjusted for inflation over the past 150 years. This data would show whether there were any previous instances where state spending decreased in real terms.\n",
      "\n",
      "4. **Expert Analysis**: Fact-checking organizations and economic historians would have analyzed such claims. For instance, PolitiFact and other fact-checking bodies often review such statements by consulting historical budget records and expert opinions.\n",
      "\n",
      "Based on available fact-checking sources, such as PolitiFact, the claim has been evaluated and found to be inaccurate. Historical records indicate that there have been other instances where state spending was cut in real terms before 2009.\n",
      "\n",
      "Final Answer: False\n",
      "Final Answer: False, Actual Answer: Mostly false\n",
      "Wrong response\n",
      "Model Output: To determine the accuracy of the claim that \"There is 'a constitutional issue' that affects 'the paychecks of members of Congress' during a shutdown,\" we need to examine the relevant constitutional provisions and how they apply during a government shutdown.\n",
      "\n",
      "The U.S. Constitution, specifically the 27th Amendment, states: \"No law, varying the compensation for the services of the Senators and Representatives, shall take effect, until an election of Representatives shall have intervened.\" This means that any changes to the pay of members of Congress cannot take effect until after the next election of the House of Representatives.\n",
      "\n",
      "During a government shutdown, many federal employees may face furloughs or delays in their paychecks. However, the pay of members of Congress is not directly affected by the shutdown because of the 27th Amendment. Their compensation cannot be altered until after the next election, ensuring that their pay remains consistent regardless of the shutdown status.\n",
      "\n",
      "Therefore, while there is a constitutional provision related to the pay of members of Congress, it does not directly cause their paychecks to be affected during a shutdown. The claim that there is \"a constitutional issue\" affecting \"the paychecks of members of Congress\" during a shutdown is misleading.\n",
      "\n",
      "Final Answer: Mostly False\n",
      "Final Answer: Mostly false, Actual Answer: True\n",
      "Wrong response\n",
      "Model Output: To determine the accuracy of the claim that James Comey suggested and CNN reported that the basis of the wiretapping warrant for Trump adviser Carter Page was \"all based on a dossier,\" we need to examine the context and details surrounding the FISA warrant and the role of the dossier.\n",
      "\n",
      "1. **James Comey's Statements**: Former FBI Director James Comey has acknowledged that the Steele dossier was part of the evidence used to obtain the FISA warrant for Carter Page. However, he has also stated that it was not the sole basis for the warrant. The FISA application included other information and evidence beyond the dossier.\n",
      "\n",
      "2. **CNN Reporting**: CNN and other news outlets have reported on the role of the Steele dossier in the FISA warrant process. These reports generally indicate that the dossier was a significant part of the application but not the only piece of evidence presented to the FISA court.\n",
      "\n",
      "3. **Inspector General Report**: The Department of Justice Inspector General's report on the FBI's FISA applications found that the Steele dossier played a central and essential role in the FBI's decision to seek the FISA order, but it also noted that the application included other information.\n",
      "\n",
      "Given this context, the claim that the warrant was \"all based on a dossier\" is an exaggeration. The dossier was a crucial part of the application, but it was not the only evidence used.\n",
      "\n",
      "Final Answer: Mostly False\n",
      "Final Answer: Mostly false, Actual Answer: Mostly false\n",
      "Correct response\n",
      "Model Output: To determine the accuracy of the claim \"Senator Jeff Plale saved my job -- and some 300 others at Bucyrus International,\" we need to examine the context and actions taken by Senator Jeff Plale regarding Bucyrus International.\n",
      "\n",
      "1. **Background Information**: Bucyrus International, a mining equipment manufacturer, was involved in a situation where jobs were at risk. The company was seeking a federal loan guarantee to support an export deal, which was initially denied by the U.S. Export-Import Bank due to environmental concerns.\n",
      "\n",
      "2. **Senator Jeff Plale's Role**: Jeff Plale, a state senator from Wisconsin, was involved in efforts to reverse the decision. He, along with other political figures, lobbied the Export-Import Bank to reconsider its decision. Their efforts were successful, and the bank eventually approved the loan guarantee, which helped secure the jobs at Bucyrus International.\n",
      "\n",
      "3. **Outcome**: The intervention by Plale and others was crucial in reversing the decision, thereby saving the jobs at Bucyrus International.\n",
      "\n",
      "Given this context, the claim that Senator Jeff Plale \"saved my job -- and some 300 others at Bucyrus International\" is supported by the fact that his actions were instrumental in securing the loan guarantee that preserved those jobs.\n",
      "\n",
      "Final Answer: Mostly True\n",
      "Final Answer: Mostly true, Actual Answer: Mostly false\n",
      "Wrong response\n",
      "Model Output: To determine the accuracy of the claim that \"The GOP health care proposal would slash more than $135 million in federal funding available to PA schools,\" we need to consider several factors:\n",
      "\n",
      "1. **Source of the Claim**: Identify the origin of the claim and whether it is based on a credible analysis or projection.\n",
      "2. **Details of the GOP Health Care Proposal**: Examine the specific provisions of the GOP health care proposal in question. This could be the American Health Care Act (AHCA) or another proposal, and we need to understand how it impacts federal funding to states, particularly for education.\n",
      "3. **Impact on Pennsylvania Schools**: Assess how the proposed changes in federal funding would specifically affect Pennsylvania schools. This involves looking at current funding levels, the role of Medicaid in school funding, and any projected cuts.\n",
      "\n",
      "### Analysis:\n",
      "\n",
      "1. **Source of the Claim**:\n",
      "   - If the claim comes from a reputable source such as a government report, a non-partisan think tank, or a well-regarded news outlet, it lends credibility to the statement.\n",
      "\n",
      "2. **GOP Health Care Proposal**:\n",
      "   - The AHCA, for example, proposed significant cuts to Medicaid. Schools receive Medicaid funding for services provided to students with disabilities and low-income students. If the proposal includes substantial Medicaid cuts, it could indeed reduce funding available to schools.\n",
      "\n",
      "3. **Impact on PA Schools**:\n",
      "   - Pennsylvania schools receive a portion of their funding from federal sources, including Medicaid. If the proposal cuts Medicaid significantly, it could result in a reduction of funds available to schools in Pennsylvania. The exact figure of $135 million would need to be verified against detailed budget analyses and projections.\n",
      "\n",
      "### Verification:\n",
      "\n",
      "- **Reports and Analyses**: Look for detailed reports from the Congressional Budget Office (CBO), state education departments, or other credible entities that have analyzed the financial impact of the GOP health care proposal on state education funding.\n",
      "- **Statements from Officials**: Statements from Pennsylvania state officials or education administrators can provide insights into the expected impact.\n",
      "\n",
      "### Conclusion:\n",
      "\n",
      "Based on the information available, if credible sources and detailed analyses support the claim that the GOP health care proposal would result in a reduction of more than $135 million in federal funding for Pennsylvania schools, the claim would be rated as 'True' or 'Mostly True'. If the evidence is mixed or less definitive, it might be rated as 'Half True'. If the claim is found to be exaggerated or unsupported by evidence, it would be rated as 'Mostly False' or 'False'.\n",
      "\n",
      "**Given the typical impact of Medicaid cuts on school funding and assuming credible sources support the figure:**\n",
      "\n",
      "Final Answer: Mostly True\n",
      "Final Answer: Mostly true, Actual Answer: False\n",
      "Wrong response\n",
      "Model Output: To determine the accuracy of the claim that a 9-year-old girl was recently raped in Austin, Texas, by a guy previously \"caught four times and released,\" we need to verify several key points:\n",
      "\n",
      "1. **Incident Verification**: Confirm if there was a recent case of a 9-year-old girl being raped in Austin, Texas.\n",
      "2. **Perpetrator's History**: Check if the alleged perpetrator had been caught four times previously and subsequently released.\n",
      "\n",
      "Without access to specific and up-to-date news reports, police records, or official statements, it is challenging to verify the details of this claim. However, based on the information available up to my knowledge cutoff in October 2021, I cannot confirm the veracity of this specific incident and the criminal history of the alleged perpetrator.\n",
      "\n",
      "Given the lack of verifiable evidence and the need for precise details to substantiate such a serious claim, the most responsible conclusion is to treat the claim with skepticism until more information is available.\n",
      "\n",
      "Final Answer: False\n",
      "Final Answer: False, Actual Answer: Half true\n",
      "Wrong response\n",
      "Model Output: To evaluate the claim, we need to compare the financial impact of extending tax cuts for the wealthy over 10 years with the cost of the Obama stimulus in one year.\n",
      "\n",
      "1. **Obama's Stimulus (American Recovery and Reinvestment Act of 2009):**\n",
      "   - The total cost of the stimulus package was approximately $787 billion, later revised to about $831 billion.\n",
      "   - This cost was spread over several years, but a significant portion was spent in the first year.\n",
      "\n",
      "2. **Extending Tax Cuts for the Wealthy:**\n",
      "   - The Bush-era tax cuts, if extended for the wealthy, were estimated to cost around $700 billion over 10 years.\n",
      "\n",
      "**Comparison:**\n",
      "- The cost of extending the tax cuts for the wealthy over 10 years ($700 billion) is indeed less than the total cost of the Obama stimulus package ($787 billion to $831 billion), even though the stimulus cost was spread over multiple years.\n",
      "\n",
      "Given this information, the claim that extending tax cuts for the wealthy over 10 years would add less to the deficit than the Obama stimulus did in one year is generally accurate, though it simplifies the distribution of the stimulus spending over time.\n",
      "\n",
      "Final Answer: Mostly True\n",
      "Final Answer: Mostly true, Actual Answer: Mostly false\n",
      "Wrong response\n",
      "Model Output: To determine the accuracy of the claim, we need to verify several key points:\n",
      "\n",
      "1. **Funding Amount**: The claim states that $160 million is being provided.\n",
      "2. **Recipient**: The state of Pennsylvania is the recipient.\n",
      "3. **Purpose**: The funds are for setting up a high-risk insurance pool program.\n",
      "4. **Coverage**: The program would cover any abortion legal in the state.\n",
      "\n",
      "**Verification Steps**:\n",
      "\n",
      "1. **Funding Amount and Recipient**: Check if the Department of Health and Human Services (HHS) has announced a $160 million grant to Pennsylvania for a high-risk insurance pool.\n",
      "2. **Purpose**: Confirm that the purpose of the funds is indeed for a high-risk insurance pool program.\n",
      "3. **Coverage of Abortions**: Verify if the program would cover any legal abortion in the state.\n",
      "\n",
      "**Research Findings**:\n",
      "\n",
      "- **High-Risk Insurance Pools**: These are typically designed to provide coverage for individuals with pre-existing conditions who have difficulty obtaining insurance.\n",
      "- **Federal Restrictions on Abortion Funding**: The Hyde Amendment restricts federal funds from being used for abortions except in cases of rape, incest, or when the life of the mother is at risk.\n",
      "\n",
      "Given these points, it is highly unlikely that federal funds would be allocated specifically to cover abortions beyond the exceptions allowed by the Hyde Amendment. \n",
      "\n",
      "**Conclusion**:\n",
      "\n",
      "Based on the information available and the restrictions imposed by the Hyde Amendment, the claim that the Department of Health and Human Services is providing $160 million to Pennsylvania specifically to cover any legal abortion in the state is highly improbable.\n",
      "\n",
      "Final Answer: False\n",
      "Final Answer: False, Actual Answer: False\n",
      "Correct response\n",
      "Model Output: To determine the accuracy of the claim that a gun bill before the Senate would make it a federal felony to \"leave town for more than seven days, and leave someone else at home with your firearms,\" we need to examine the specific provisions of the bill in question.\n",
      "\n",
      "1. **Context and Source**: Identify the specific bill being referenced. Often, claims about legislation can be traced back to a particular bill or proposal. Without knowing the exact bill, we can look at general trends in recent gun control legislation.\n",
      "\n",
      "2. **Legislative Text**: Review the actual text of the bill. Legislative language can be complex, but it is crucial to see if the bill explicitly states that leaving town for more than seven days and leaving firearms with someone else would be a federal felony.\n",
      "\n",
      "3. **Interpretation and Intent**: Understand the intent behind the bill. Sometimes, the language in a bill can be misinterpreted or taken out of context. For example, a bill might have provisions about the secure storage of firearms or background checks for temporary transfers, but not necessarily criminalize the act described in the claim.\n",
      "\n",
      "4. **Expert Analysis**: Look for analyses or fact-checks from reliable sources. Organizations that specialize in legislative analysis or fact-checking can provide insights into the accuracy of such claims.\n",
      "\n",
      "Given the complexity and the need for precise information, let's consider a hypothetical recent bill, such as H.R. 8 (the Bipartisan Background Checks Act of 2021), which aims to expand background checks for firearm transfers. This bill does not make it a federal felony to leave town and leave firearms with someone else, but it does require background checks for most firearm transfers, with certain exceptions.\n",
      "\n",
      "Based on this approach, the claim appears to be an exaggeration or misinterpretation of the bill's provisions.\n",
      "\n",
      "Final Answer: 'False'\n",
      "Final Answer: False, Actual Answer: Half true\n",
      "Wrong response\n",
      "Model Output: To determine the accuracy of the claim that \"The bulk of the people who are shot with a weapon — other than these drug gangs taking on one another — end up being shot with their own weapon,\" we need to examine available data and research on firearm-related injuries and deaths.\n",
      "\n",
      "1. **Self-Inflicted Gunshot Wounds**: According to data from the Centers for Disease Control and Prevention (CDC), a significant portion of gun-related deaths are suicides. In many of these cases, individuals use their own firearms.\n",
      "\n",
      "2. **Accidental Shootings**: There are also instances of accidental shootings where individuals are injured or killed by their own weapons.\n",
      "\n",
      "3. **Domestic Violence**: In cases of domestic violence, it is not uncommon for the victim to be shot with a weapon that is owned by someone in the household, which could be considered their own weapon in a broader sense.\n",
      "\n",
      "4. **Criminal Activity**: For non-gang-related criminal activity, there is less clear data on whether victims are predominantly shot with their own weapons. However, it is known that in some cases, assailants use the victim's weapon against them.\n",
      "\n",
      "5. **Research and Expert Opinions**: Various studies and expert opinions suggest that while a notable number of people are shot with their own weapons, it is not necessarily the \"bulk\" of all non-gang-related shootings. The claim may be an overstatement without specific statistical backing.\n",
      "\n",
      "Given the complexity and the need for more precise data to support the claim fully, it appears that the statement may be an exaggeration of the actual situation.\n",
      "\n",
      "Final Answer: Mostly False\n",
      "Final Answer: Mostly false, Actual Answer: Half true\n",
      "Wrong response\n",
      "Model Output: To determine the accuracy of the claim \"Right now, American oil production is the highest that it’s been in eight years,\" we need to look at historical data on U.S. oil production.\n",
      "\n",
      "1. **Historical Data**: Check the U.S. Energy Information Administration (EIA) for historical oil production data. The EIA provides monthly and annual data on U.S. crude oil production.\n",
      "\n",
      "2. **Current Production Levels**: Verify the most recent data available to see the current level of oil production.\n",
      "\n",
      "3. **Comparison**: Compare the current production levels to those from the past eight years to see if the current level is indeed the highest.\n",
      "\n",
      "As of the latest data available in 2023, U.S. oil production has been increasing and has reached high levels, but it is essential to compare it specifically to the past eight years to confirm the claim.\n",
      "\n",
      "Based on the most recent data from the EIA, U.S. oil production has seen significant increases, especially after the COVID-19 pandemic recovery. However, it is crucial to note that U.S. oil production reached a peak in 2019 before the pandemic, and while current production levels are high, they may not necessarily surpass the peak levels of 2019.\n",
      "\n",
      "**Analysis**:\n",
      "- If the current production is higher than any year in the past eight years, the claim is true.\n",
      "- If the current production is high but not the highest in the past eight years, the claim is mostly true or half true depending on how close it is to the peak.\n",
      "\n",
      "Given the data trends and the likelihood that current production is high but not necessarily the highest in the past eight years, the claim is likely to be:\n",
      "\n",
      "Final Answer: Mostly True\n",
      "Final Answer: Mostly true, Actual Answer: Mostly true\n",
      "Correct response\n",
      "Model Output: To determine the accuracy of the claim that \"More than 10 years of free trade has brought a $2 billion per day trade deficit,\" we need to examine the context and data related to the U.S. trade deficit over the past decade.\n",
      "\n",
      "1. **Trade Deficit Data**: According to the U.S. Census Bureau, the U.S. trade deficit has varied over the years. For example, in 2022, the U.S. trade deficit was approximately $948 billion for the entire year. Dividing this by 365 days gives an average daily trade deficit of about $2.6 billion.\n",
      "\n",
      "2. **Free Trade Agreements**: The U.S. has been involved in various free trade agreements (FTAs) over the past decade, including NAFTA (now USMCA), agreements with South Korea, Colombia, and others. These agreements aim to reduce trade barriers and increase trade flows.\n",
      "\n",
      "3. **Time Frame**: The claim mentions \"more than 10 years,\" which would cover a period from around 2012 to 2022. During this period, the U.S. has seen significant trade deficits, but the exact daily average can fluctuate based on annual data.\n",
      "\n",
      "4. **Context of Free Trade**: While free trade agreements can influence trade balances, they are not the sole factor. Other elements such as global economic conditions, currency exchange rates, and domestic economic policies also play significant roles.\n",
      "\n",
      "Given the data and context, the claim that free trade over the past decade has resulted in a $2 billion per day trade deficit is somewhat accurate but lacks nuance. The trade deficit has indeed been substantial, and the average daily figure aligns with the claim, but attributing it solely to free trade agreements oversimplifies the issue.\n",
      "\n",
      "Final Answer: Half True\n",
      "Final Answer: Half true, Actual Answer: Mostly true\n",
      "Wrong response\n",
      "Model Output: To evaluate the claim that the United States is \"the Saudi Arabia of coal,\" we need to consider the context and the basis of the comparison. Saudi Arabia is known for its vast oil reserves and its significant role in the global oil market. Similarly, the United States has substantial coal reserves and has historically been a major player in the global coal market.\n",
      "\n",
      "1. **Coal Reserves**: The United States has the largest proven coal reserves in the world. According to the U.S. Energy Information Administration (EIA), the U.S. holds about 22% of the world's proven coal reserves.\n",
      "\n",
      "2. **Production**: The U.S. is one of the top coal producers globally, although its production has declined in recent years due to a shift towards cleaner energy sources and natural gas.\n",
      "\n",
      "3. **Exports**: While the U.S. exports a significant amount of coal, it is not the largest coal exporter. Countries like Australia and Indonesia export more coal than the U.S.\n",
      "\n",
      "Given these points, the claim that the United States is \"the Saudi Arabia of coal\" is an analogy that highlights the U.S.'s significant coal reserves and its historical importance in coal production. However, it may overstate the current global influence of the U.S. in the coal market compared to Saudi Arabia's influence in the oil market.\n",
      "\n",
      "Final Answer: Mostly True\n",
      "Final Answer: Mostly true, Actual Answer: Mostly true\n",
      "Correct response\n",
      "Model Output: To determine the accuracy of the claim that \"Members of the public are being charged $50 to hear Gov. Scott Walker and a dozen members of his administration talk about jobs and the economy at Lambeau Field,\" we need to verify several key points:\n",
      "\n",
      "1. Whether Gov. Scott Walker and members of his administration are indeed scheduled to speak at Lambeau Field.\n",
      "2. Whether the topic of discussion is jobs and the economy.\n",
      "3. Whether members of the public are being charged $50 to attend the event.\n",
      "\n",
      "If all these points are confirmed, the claim would be 'True'. If some elements are accurate but others are not, the rating would vary accordingly.\n",
      "\n",
      "Given the information provided, and assuming no additional context or details that might alter the interpretation, the claim appears to be straightforward and specific.\n",
      "\n",
      "Final Answer: True\n",
      "Final Answer: True, Actual Answer: True\n",
      "Correct response\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve the OpenAI API key from the environment variable\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Define the prompting method and language family\n",
    "language_family = \"english\"\n",
    "method = \"direct_inference\"\n",
    "model = \"gpt-4o\"\n",
    "\n",
    "# Load data\n",
    "input_file_path = f'../../Translated JSON Files/{language_family}.json'\n",
    "output_file_path = f\"{language_family}_{model}_{method}.csv\"\n",
    "summary_file_path = f\"{language_family}_{model}_{method}_summary.json\"\n",
    "\n",
    "if os.path.exists(input_file_path):\n",
    "    with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "else:\n",
    "    raise FileNotFoundError(f\"File not found: {input_file_path}\")\n",
    "\n",
    "claims = [item['claim'] for item in data]\n",
    "labels = [item['label'] for item in data]\n",
    "languages = [item['language'] for item in data]\n",
    "sites = [item['site'] for item in data]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'claim': claims,\n",
    "    'label': labels,\n",
    "    'language': languages,\n",
    "    'site': sites\n",
    "})\n",
    "\n",
    "def get_gpt_response(claim, model=model):\n",
    "    user_prompt = f\"'{claim}' Is this claim 'True', 'Mostly True', 'Half True', 'Mostly False', or 'False'? You must always make sure your final response is prefixed with 'Final Answer:' followed by either 'True', 'Mostly True', 'Half True', 'Mostly False', or 'False'.\"\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response['choices'][0]['message']['content']\n",
    "\n",
    "# Initialize or load existing outputs and summary\n",
    "if os.path.exists(output_file_path):\n",
    "    output_df = pd.read_csv(output_file_path)\n",
    "    outputs = output_df.to_dict('records')\n",
    "else:\n",
    "    outputs = []\n",
    "\n",
    "if os.path.exists(summary_file_path):\n",
    "    with open(summary_file_path, 'r', encoding='utf-8') as file:\n",
    "        summary = json.load(file)\n",
    "else:\n",
    "    summary = {\n",
    "        'correct': 0,\n",
    "        'wrong': 0,\n",
    "        'inconclusive': 0,\n",
    "        'total': 0,\n",
    "        'languages': {}\n",
    "    }\n",
    "\n",
    "# Function to clean the output text\n",
    "def clean_output(output):\n",
    "    # Remove non-alphanumeric characters except spaces\n",
    "    cleaned_output = re.sub(r'[^a-zA-Z\\s]', '', output)\n",
    "    return cleaned_output\n",
    "\n",
    "# Process claims and update files iteratively\n",
    "for index, row in df.iterrows():\n",
    "    if any(output['claim'] == row['claim'] for output in outputs):\n",
    "        continue  # Skip already processed claims\n",
    "\n",
    "    claim = row['claim']\n",
    "    label = row['label']\n",
    "    language = row['language']\n",
    "    output = get_gpt_response(claim)\n",
    "    \n",
    "    # Print the model's output\n",
    "    print(f\"Model Output: {output}\")\n",
    "    \n",
    "    # Clean the output\n",
    "    cleaned_output = clean_output(output)\n",
    "    \n",
    "    # Extract final answer from the cleaned output\n",
    "    final_answer = None\n",
    "    if \"final answer true\" in cleaned_output.lower():\n",
    "        final_answer = \"true\"\n",
    "    elif \"final answer false\" in cleaned_output.lower():\n",
    "        final_answer = \"false\"\n",
    "    elif \"final answer mostly true\" in cleaned_output.lower():\n",
    "        final_answer = \"mostly true\"\n",
    "    elif \"final answer mostly false\" in cleaned_output.lower():\n",
    "        final_answer = \"mostly false\"\n",
    "    elif \"final answer half true\" in cleaned_output.lower():\n",
    "        final_answer = \"half true\"\n",
    "    \n",
    "    # Determine correctness or inconclusiveness\n",
    "    if final_answer is None:\n",
    "        print(\"Inconclusive response\")\n",
    "        summary['inconclusive'] += 1\n",
    "    else:\n",
    "        print(f\"Final Answer: {final_answer.capitalize()}, Actual Answer: {label.capitalize()}\")\n",
    "        if final_answer == label.lower():\n",
    "            print(\"Correct response\")\n",
    "            summary['correct'] += 1\n",
    "        else:\n",
    "            print(\"Wrong response\")\n",
    "            summary['wrong'] += 1\n",
    "    \n",
    "    # Save outputs\n",
    "    output_record = {\n",
    "        'claim': claim,\n",
    "        'label': label,\n",
    "        'language': language,\n",
    "        'output': output,\n",
    "        'final_answer': final_answer,\n",
    "        'correct': final_answer == label.lower() if final_answer else False,\n",
    "        'inconclusive': final_answer is None\n",
    "    }\n",
    "    outputs.append(output_record)\n",
    "    \n",
    "    # Update language summary\n",
    "    if language not in summary['languages']:\n",
    "        summary['languages'][language] = {'correct': 0, 'wrong': 0, 'inconclusive': 0, 'total': 0}\n",
    "    summary['languages'][language]['total'] += 1\n",
    "    summary['total'] += 1\n",
    "    if final_answer is None:\n",
    "        summary['languages'][language]['inconclusive'] += 1\n",
    "    elif final_answer == label.lower():\n",
    "        summary['languages'][language]['correct'] += 1\n",
    "    else:\n",
    "        summary['languages'][language]['wrong'] += 1\n",
    "\n",
    "    # Save results to CSV iteratively\n",
    "    pd.DataFrame(outputs).to_csv(output_file_path, index=False, encoding='utf-8')\n",
    "\n",
    "    # Save summary to JSON iteratively\n",
    "    with open(summary_file_path, 'w', encoding='utf-8') as file:\n",
    "        json.dump(summary, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Results saved to {output_file_path} and {summary_file_path}\")\n",
    "print(f\"Summary: {summary}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Romance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve the OpenAI API key from the environment variable\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Define the prompting method and language family\n",
    "language_family = \"romance\"\n",
    "method = \"direct_inference\"\n",
    "model = \"gpt-4o\"\n",
    "\n",
    "# Load data\n",
    "input_file_path = f'../../Translated JSON Files/{language_family}.json'\n",
    "output_file_path = f\"{language_family}_{model}_{method}.csv\"\n",
    "summary_file_path = f\"{language_family}_{model}_{method}_summary.json\"\n",
    "\n",
    "if os.path.exists(input_file_path):\n",
    "    with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "else:\n",
    "    raise FileNotFoundError(f\"File not found: {input_file_path}\")\n",
    "\n",
    "claims = [item['claim'] for item in data]\n",
    "labels = [item['label'] for item in data]\n",
    "languages = [item['language'] for item in data]\n",
    "sites = [item['site'] for item in data]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'claim': claims,\n",
    "    'label': labels,\n",
    "    'language': languages,\n",
    "    'site': sites\n",
    "})\n",
    "\n",
    "# Language-specific user prompts and final answer mappings\n",
    "prompts = {\n",
    "    \"es\": \"'{claim}' ¿Es esta afirmación «Verdadera», «Casi verdadera», «Medio verdadera», «Casi falsa» o «Falsa»? Debe asegurarse de que su respuesta final comience con «Respuesta final:» seguida de «Verdadero», «Casi verdadero», «Medio verdadero», «Casi falso» o «Falso».\",\n",
    "    \"it\": \"'{claim}' Questa affermazione è “vera”, “quasi vera”, “mezza vera”, “quasi falsa” o “falsa”? Assicurati che la tua risposta finale inizi con “Risposta finale:” seguita da “Vero”, “Quasi vero”, “Mezzo vero”, “Quasi falso” o “Falso”.\",\n",
    "    \"pt\": \"'{claim}' Esta afirmação é “Verdadeira”, “Quase Verdadeira”, “Meia Verdadeira”, “Quase Falsa” ou “Falsa”? Certifique-se de que sua resposta final comece com “Resposta Final:” seguida de “Verdadeiro”, “Quase Verdadeiro”, “Meio Verdadeiro”, “Quase Falso” ou “Falso”.\",\n",
    "    \"fr\": \"'{claim}' Cette affirmation est-elle « vraie », « en grande partie vraie », « à moitié vraie », « en grande partie fausse » ou « fausse » ? Vous devez vous assurer que votre réponse finale commence par « Réponse finale: » suivie de « Vrai », « En grande partie vrai », « À moitié vrai », « En grande partie faux » ou « Faux ».\"\n",
    "}\n",
    "\n",
    "final_answer_mappings = {\n",
    "    \"es\": {\n",
    "        \"respuesta final: verdadero\": \"true\", \"respuesta final: verdadera\": \"true\",\n",
    "        \"respuesta final: casi verdadero\": \"mostly true\", \"respuesta final: casi verdadera\": \"mostly true\",\n",
    "        \"respuesta final: medio verdadero\": \"half true\", \"respuesta final: medio verdadera\": \"half true\",\n",
    "        \"respuesta final: casi falso\": \"mostly false\", \"respuesta final: casi falsa\": \"mostly false\",\n",
    "        \"respuesta final: falso\": \"false\", \"respuesta final: falsa\": \"false\",\n",
    "        \"verdadero\": \"true\", \"verdadera\": \"true\",\n",
    "        \"casi verdadero\": \"mostly true\", \"casi verdadera\": \"mostly true\",\n",
    "        \"medio verdadero\": \"half true\", \"medio verdadera\": \"half true\",\n",
    "        \"casi falso\": \"mostly false\", \"casi falsa\": \"mostly false\",\n",
    "        \"falso\": \"false\", \"falsa\": \"false\"\n",
    "    },\n",
    "    \"it\": {\n",
    "        \"risposta finale: vero\": \"true\", \"risposta finale: vera\": \"true\",\n",
    "        \"risposta finale: quasi vero\": \"mostly true\", \"risposta finale: quasi vera\": \"mostly true\",\n",
    "        \"risposta finale: mezzo vero\": \"half true\", \"risposta finale: mezza vera\": \"half true\",\n",
    "        \"risposta finale: quasi falso\": \"mostly false\", \"risposta finale: quasi falsa\": \"mostly false\",\n",
    "        \"risposta finale: falso\": \"false\", \"risposta finale: falsa\": \"false\",\n",
    "        \"vero\": \"true\", \"vera\": \"true\",\n",
    "        \"quasi vero\": \"mostly true\", \"quasi vera\": \"mostly true\",\n",
    "        \"mezzo vero\": \"half true\", \"mezza vera\": \"half true\",\n",
    "        \"quasi falso\": \"mostly false\", \"quasi falsa\": \"mostly false\",\n",
    "        \"falso\": \"false\", \"falsa\": \"false\"\n",
    "    },\n",
    "    \"pt\": {\n",
    "        \"resposta final: verdadeiro\": \"true\", \"resposta final: verdadeira\": \"true\",\n",
    "        \"resposta final: quase verdadeiro\": \"mostly true\", \"resposta final: quase verdadeira\": \"mostly true\",\n",
    "        \"resposta final: meio verdadeiro\": \"half true\", \"resposta final: meia verdadeira\": \"half true\",\n",
    "        \"resposta final: quase falso\": \"mostly false\", \"resposta final: quase falsa\": \"mostly false\",\n",
    "        \"resposta final: falso\": \"false\", \"resposta final: falsa\": \"false\",\n",
    "        \"verdadeiro\": \"true\", \"verdadeira\": \"true\",\n",
    "        \"quase verdadeiro\": \"mostly true\", \"quase verdadeira\": \"mostly true\",\n",
    "        \"meio verdadeiro\": \"half true\", \"meia verdadeira\": \"half true\",\n",
    "        \"quase falso\": \"mostly false\", \"quase falsa\": \"mostly false\",\n",
    "        \"falso\": \"false\", \"falsa\": \"false\"\n",
    "    },\n",
    "    \"fr\": {\n",
    "        \"réponse finale: vrai\": \"true\", \"réponse finale: vraie\": \"true\",\n",
    "        \"réponse finale: plus ou moins vrai\": \"mostly true\", \"réponse finale: plus ou moins vraie\": \"mostly true\",\n",
    "        \"réponse finale: moitié vrai\": \"half true\", \"réponse finale: moitié vraie\": \"half true\",\n",
    "        \"réponse finale: plus ou moins faux\": \"mostly false\", \"réponse finale: plus ou moins fausse\": \"mostly false\",\n",
    "        \"réponse finale: faux\": \"false\", \"réponse finale: fausse\": \"false\",\n",
    "        \"vrai\": \"true\", \"vraie\": \"true\",\n",
    "        \"plus ou moins vrai\": \"mostly true\", \"plus ou moins vraie\": \"mostly true\",\n",
    "        \"moitié vrai\": \"half true\", \"moitié vraie\": \"half true\",\n",
    "        \"plus ou moins faux\": \"mostly false\", \"plus ou moins fausse\": \"mostly false\",\n",
    "        \"faux\": \"false\", \"fausse\": \"false\"\n",
    "    }\n",
    "}\n",
    "\n",
    "def get_gpt_response(claim, language, model=model):\n",
    "    try:\n",
    "        user_prompt = prompts[language].format(claim=claim)\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0,\n",
    "        )\n",
    "        return response['choices'][0]['message']['content']\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting GPT response: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def clean_output(output):\n",
    "    cleaned_output = re.sub(r'[^a-zA-Z\\s:]', '', output)\n",
    "    return cleaned_output.lower()\n",
    "\n",
    "def extract_final_answer(cleaned_output, language):\n",
    "    try:\n",
    "        final_answer = re.search(r'(respuesta final:|risposta finale:|resposta final:|réponse finale:)\\s*([\\w\\s]+)', cleaned_output)\n",
    "        if final_answer:\n",
    "            response = final_answer.group(2).strip()\n",
    "            for keyword, answer in final_answer_mappings[language].items():\n",
    "                if keyword in response:\n",
    "                    return answer\n",
    "        else:\n",
    "            for keyword, answer in final_answer_mappings[language].items():\n",
    "                if keyword in cleaned_output:\n",
    "                    return answer\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting final answer: {e}\")\n",
    "    return None\n",
    "\n",
    "# Initialize or load existing outputs and summary\n",
    "if os.path.exists(output_file_path):\n",
    "    output_df = pd.read_csv(output_file_path)\n",
    "    outputs = output_df.to_dict('records')\n",
    "else:\n",
    "    outputs = []\n",
    "\n",
    "if os.path.exists(summary_file_path):\n",
    "    with open(summary_file_path, 'r', encoding='utf-8') as file:\n",
    "        summary = json.load(file)\n",
    "else:\n",
    "    summary = {\n",
    "        'correct': 0,\n",
    "        'wrong': 0,\n",
    "        'inconclusive': 0,\n",
    "        'total': 0,\n",
    "        'languages': {}\n",
    "    }\n",
    "\n",
    "# Process claims and update files iteratively\n",
    "for index, row in df.iterrows():\n",
    "    if any(output['claim'] == row['claim'] for output in outputs):\n",
    "        continue  # Skip already processed claims\n",
    "\n",
    "    claim = row['claim']\n",
    "    label = row['label']\n",
    "    language = row['language']\n",
    "    \n",
    "    if language not in prompts:  # Skip unsupported languages\n",
    "        continue\n",
    "\n",
    "    output = get_gpt_response(claim, language)\n",
    "    \n",
    "    print(f\"Model Output: {output}\")\n",
    "    \n",
    "    cleaned_output = clean_output(output)\n",
    "    final_answer = extract_final_answer(cleaned_output, language)\n",
    "    \n",
    "    if final_answer is None:\n",
    "        print(\"Inconclusive response\")\n",
    "        summary['inconclusive'] += 1\n",
    "    else:\n",
    "        print(f\"Final Answer: {final_answer.capitalize()}, Actual Answer: {label.capitalize()}\")\n",
    "        if final_answer == label.lower():\n",
    "            print(\"Correct response\")\n",
    "            summary['correct'] += 1\n",
    "        else:\n",
    "            print(\"Wrong response\")\n",
    "            summary['wrong'] += 1\n",
    "    \n",
    "    # Save outputs\n",
    "    output_record = {\n",
    "        'claim': claim,\n",
    "        'label': label,\n",
    "        'language': language,\n",
    "        'output': output,\n",
    "        'final_answer': final_answer,\n",
    "        'correct': final_answer == label.lower() if final_answer else False,\n",
    "        'inconclusive': final_answer is None\n",
    "    }\n",
    "    outputs.append(output_record)\n",
    "    \n",
    "    # Update language summary\n",
    "    if language not in summary['languages']:\n",
    "        summary['languages'][language] = {'correct': 0, 'wrong': 0, 'inconclusive': 0, 'total': 0}\n",
    "    summary['languages'][language]['total'] += 1\n",
    "    summary['total'] += 1\n",
    "    if final_answer is None:\n",
    "        summary['languages'][language]['inconclusive'] += 1\n",
    "    elif final_answer == label.lower():\n",
    "        summary['languages'][language]['correct'] += 1\n",
    "    else:\n",
    "        summary['languages'][language]['wrong'] += 1\n",
    "\n",
    "    # Save results to CSV iteratively\n",
    "    pd.DataFrame(outputs).to_csv(output_file_path, index=False, encoding='utf-8')\n",
    "\n",
    "    # Save summary to JSON iteratively\n",
    "    with open(summary_file_path, 'w', encoding='utf-8') as file:\n",
    "        json.dump(summary, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Results saved to {output_file_path} and {summary_file_path}\")\n",
    "print(f\"Summary: {summary}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indo-Aryan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve the OpenAI API key from the environment variable\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Define the prompting method and language family\n",
    "language_family = \"indo_aryan\"\n",
    "method = \"direct_inference\"\n",
    "model = \"gpt-4o\"\n",
    "\n",
    "# Load data\n",
    "input_file_path = f'../../Translated JSON Files/{language_family}.json'\n",
    "output_file_path = f\"{language_family}_{model}_{method}.csv\"\n",
    "summary_file_path = f\"{language_family}_{model}_{method}_summary.json\"\n",
    "\n",
    "if os.path.exists(input_file_path):\n",
    "    with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "else:\n",
    "    raise FileNotFoundError(f\"File not found: {input_file_path}\")\n",
    "\n",
    "claims = [item['claim'] for item in data]\n",
    "labels = [item['label'] for item in data]\n",
    "languages = [item['language'] for item in data]\n",
    "sites = [item['site'] for item in data]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'claim': claims,\n",
    "    'label': labels,\n",
    "    'language': languages,\n",
    "    'site': sites\n",
    "})\n",
    "\n",
    "# Language-specific user prompts and final answer mappings\n",
    "prompts = {\n",
    "    \"hi\": \"'{claim}' क्या यह कथन «सत्य», «अधिकांशतः सत्य», «आधा सत्य», «अधिकांशतः असत्य» या «असत्य» है? आपको हमेशा यह सुनिश्चित करना चाहिए कि आपका अंतिम उत्तर «अंतिम उत्तर:» के साथ शुरू हो और उसके बाद «सत्य», «अधिकांशतः सत्य», «आधा सत्य», «अधिकांशतः असत्य» या «असत्य» हो।\",\n",
    "    \"bn\": \"'{claim}' এই বক্তব্যটি «সত্য», «অধিকাংশ সত্য», «অর্ধসত্য», «অধিকাংশ মিথ্যা» বা «মিথ্যা» কি? সর্বদা নিশ্চিত করুন যে আপনার চূড়ান্ত উত্তর «চূড়ান্ত উত্তর:» দিয়ে শুরু হয় এবং তারপরে «সত্য», «অধিকাংশ সত্য», «অর্ধসত্য», «অধিকাংশ মিথ্যা» বা «মিথ্যা»।\",\n",
    "    \"pa\": \"'{claim}' ਕੀ ਇਹ ਬਿਆਨ «ਸੱਚ», «ਜਿਆਦਾਤਰ ਸੱਚ», «ਅੱਧਾ ਸੱਚ», «ਜਿਆਦਾਤਰ ਝੂਠ» ਜਾਂ «ਝੂਠ» ਹੈ? ਤੁਹਾਨੂੰ ਹਮੇਸ਼ਾਂ ਇਹ ਯਕੀਨੀ ਬਣਾਉਣਾ ਚਾਹੀਦਾ ਹੈ ਕਿ ਤੁਹਾਡਾ ਅੰਤਿਮ ਜਵਾਬ «ਅੰਤਿਮ ਜਵਾਬ:» ਨਾਲ ਸ਼ੁਰੂ ਹੋਵੇ ਅਤੇ ਫਿਰ «ਸੱਚ», «ਜਿਆਦਾਤਰ ਸੱਚ», «ਅੱਧਾ ਸੱਚ», «ਜਿਆਦਾਤਰ ਝੂਠ» ਜਾਂ «ਝੂਠ» ਹੋਵੇ।\",\n",
    "    \"gu\": \"'{claim}' શું આ નિવેદન «સત્ય», «મોટાભાગનું સત્ય», «અડધું સત્ય», «મોટાભાગનું ખોટું» કે «ખોટું» છે? તમે હંમેશાં ખાતરી કરવી જોઈએ કે તમારો અંતિમ જવાબ «અંતિમ જવાબ:» થી શરૂ થાય અને પછી «સત્ય», «મોટાભાગનું સત્ય», «અડધું સત્ય», «મોટાભાગનું ખોટું» કે «ખોટું» આવે।\",\n",
    "    \"mr\": \"'{claim}' हे विधान «सत्य», «जास्तीत जास्त सत्य», «अर्धसत्य», «जास्तीत जास्त असत्य» किंवा «असत्य» आहे का? तुम्ही नेहमी हे सुनिश्चित केले पाहिजे की तुमचे अंतिम उत्तर «अंतिम उत्तर:» ने सुरू होते आणि त्यानंतर «सत्य», «जास्तीत जास्त सत्य», «अर्धसत्य», «जास्तीत जास्त असत्य» किंवा «असत्य» येते.\"\n",
    "}\n",
    "\n",
    "final_answer_mappings = {\n",
    "    \"hi\": {\n",
    "        \"अंतिम उत्तर: सत्य\": \"true\",\n",
    "        \"अंतिम उत्तर: अधिकांशतः सत्य\": \"mostly true\",\n",
    "        \"अंतिम उत्तर: आधा सत्य\": \"half true\",\n",
    "        \"अंतिम उत्तर: अधिकांशतः असत्य\": \"mostly false\",\n",
    "        \"अंतिम उत्तर: असत्य\": \"false\",\n",
    "        \"सत्य\": \"true\",\n",
    "        \"अधिकांशतः सत्य\": \"mostly true\",\n",
    "        \"आधा सत्य\": \"half true\",\n",
    "        \"अधिकांशतः असत्य\": \"mostly false\",\n",
    "        \"असत्य\": \"false\"\n",
    "    },\n",
    "    \"bn\": {\n",
    "        \"চূড়ান্ত উত্তর: সত্য\": \"true\",\n",
    "        \"চূড়ান্ত উত্তর: অধিকাংশ সত্য\": \"mostly true\",\n",
    "        \"চূড়ান্ত উত্তর: অর্ধসত্য\": \"half true\",\n",
    "        \"চূড়ান্ত উত্তর: অধিকাংশ মিথ্যা\": \"mostly false\",\n",
    "        \"চূড়ান্ত উত্তর: মিথ্যা\": \"false\",\n",
    "        \"সত্য\": \"true\",\n",
    "        \"অধিকাংশ সত্য\": \"mostly true\",\n",
    "        \"অর্ধসত্য\": \"half true\",\n",
    "        \"অধিকাংশ মিথ্যা\": \"mostly false\",\n",
    "        \"মিথ্যা\": \"false\"\n",
    "    },\n",
    "    \"pa\": {\n",
    "        \"ਅੰਤਿਮ ਜਵਾਬ: ਸੱਚ\": \"true\",\n",
    "        \"ਅੰਤਿਮ ਜਵਾਬ: ਜਿਆਦਾਤਰ ਸੱਚ\": \"mostly true\",\n",
    "        \"ਅੰਤਿਮ ਜਵਾਬ: ਅੱਧਾ ਸੱਚ\": \"half true\",\n",
    "        \"ਅੰਤਿਮ ਜਵਾਬ: ਜਿਆਦਾਤਰ ਝੂਠ\": \"mostly false\",\n",
    "        \"ਅੰਤਿਮ ਜਵਾਬ: ਝੂਠ\": \"false\",\n",
    "        \"ਸੱਚ\": \"true\",\n",
    "        \"ਜਿਆਦਾਤਰ ਸੱਚ\": \"mostly true\",\n",
    "        \"ਅੱਧਾ ਸੱਚ\": \"half true\",\n",
    "        \"ਜਿਆਦਾਤਰ ਝੂਠ\": \"mostly false\",\n",
    "        \"ਝੂਠ\": \"false\"\n",
    "    },\n",
    "    \"gu\": {\n",
    "        \"અંતિમ જવાબ: સત્ય\": \"true\",\n",
    "        \"અંતિમ જવાબ: મોટાભાગનું સત્ય\": \"mostly true\",\n",
    "        \"અંતિમ જવાબ: અડધું સત્ય\": \"half true\",\n",
    "        \"અંતિમ જવાબ: મોટાભાગનું ખોટું\": \"mostly false\",\n",
    "        \"અંતિમ જવાબ: ખોટું\": \"false\",\n",
    "        \"સત્ય\": \"true\",\n",
    "        \"મોટાભાગનું સત્ય\": \"mostly true\",\n",
    "        \"અડધું સત્ય\": \"half true\",\n",
    "        \"મોટાભાગનું ખોટું\": \"mostly false\",\n",
    "        \"ખોટું\": \"false\"\n",
    "    },\n",
    "    \"mr\": {\n",
    "        \"अंतिम उत्तर: सत्य\": \"true\",\n",
    "        \"अंतिम उत्तर: जास्तीत जास्त सत्य\": \"mostly true\",\n",
    "        \"अंतिम उत्तर: अर्धसत्य\": \"half true\",\n",
    "        \"अंतिम उत्तर: जास्तीत जास्त असत्य\": \"mostly false\",\n",
    "        \"अंतिम उत्तर: असत्य\": \"false\",\n",
    "        \"सत्य\": \"true\",\n",
    "        \"जास्तीत जास्त सत्य\": \"mostly true\",\n",
    "        \"अर्धसत्य\": \"half true\",\n",
    "        \"जास्तीत जास्त असत्य\": \"mostly false\",\n",
    "        \"असत्य\": \"false\"\n",
    "    }\n",
    "}\n",
    "\n",
    "def get_gpt_response(claim, language, model=model):\n",
    "    try:\n",
    "        user_prompt = prompts[language].format(claim=claim)\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0,\n",
    "        )\n",
    "        return response['choices'][0]['message']['content']\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting GPT response: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def clean_output(output):\n",
    "    cleaned_output = re.sub(r'[^a-zA-Z\\s:]', '', output)\n",
    "    return cleaned_output.lower()\n",
    "\n",
    "def extract_final_answer(cleaned_output, language):\n",
    "    try:\n",
    "        final_answer = re.search(r'(अंतिम उत्तर:|चূড়ান্ত উত্তর:|ਅੰਤਿਮ ਜਵਾਬ:|અંતિમ જવાબ:|अंतिम उत्तर:)\\s*([\\w\\s]+)', cleaned_output)\n",
    "        if final_answer:\n",
    "            response = final_answer.group(2).strip()\n",
    "            for keyword, answer in final_answer_mappings[language].items():\n",
    "                if keyword in response:\n",
    "                    return answer\n",
    "        else:\n",
    "            for keyword, answer in final_answer_mappings[language].items():\n",
    "                if keyword in cleaned_output:\n",
    "                    return answer\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting final answer: {e}\")\n",
    "    return None\n",
    "\n",
    "# Initialize or load existing outputs and summary\n",
    "if os.path.exists(output_file_path):\n",
    "    output_df = pd.read_csv(output_file_path)\n",
    "    outputs = output_df.to_dict('records')\n",
    "else:\n",
    "    outputs = []\n",
    "\n",
    "if os.path.exists(summary_file_path):\n",
    "    with open(summary_file_path, 'r', encoding='utf-8') as file:\n",
    "        summary = json.load(file)\n",
    "else:\n",
    "    summary = {\n",
    "        'correct': 0,\n",
    "        'wrong': 0,\n",
    "        'inconclusive': 0,\n",
    "        'total': 0,\n",
    "        'languages': {}\n",
    "    }\n",
    "\n",
    "# Process claims and update files iteratively\n",
    "for index, row in df.iterrows():\n",
    "    if any(output['claim'] == row['claim'] for output in outputs):\n",
    "        continue  # Skip already processed claims\n",
    "\n",
    "    claim = row['claim']\n",
    "    label = row['label']\n",
    "    language = row['language']\n",
    "    \n",
    "    if language not in prompts:  # Skip unsupported languages\n",
    "        continue\n",
    "\n",
    "    output = get_gpt_response(claim, language)\n",
    "    \n",
    "    print(f\"Model Output: {output}\")\n",
    "    \n",
    "    cleaned_output = clean_output(output)\n",
    "    final_answer = extract_final_answer(cleaned_output, language)\n",
    "    \n",
    "    if final_answer is None:\n",
    "        print(\"Inconclusive response\")\n",
    "        summary['inconclusive'] += 1\n",
    "    else:\n",
    "        print(f\"Final Answer: {final_answer.capitalize()}, Actual Answer: {label.capitalize()}\")\n",
    "        if final_answer == label.lower():\n",
    "            print(\"Correct response\")\n",
    "            summary['correct'] += 1\n",
    "        else:\n",
    "            print(\"Wrong response\")\n",
    "            summary['wrong'] += 1\n",
    "    \n",
    "    # Save outputs\n",
    "    output_record = {\n",
    "        'claim': claim,\n",
    "        'label': label,\n",
    "        'language': language,\n",
    "        'output': output,\n",
    "        'final_answer': final_answer,\n",
    "        'correct': final_answer == label.lower() if final_answer else False,\n",
    "        'inconclusive': final_answer is None\n",
    "    }\n",
    "    outputs.append(output_record)\n",
    "    \n",
    "    # Update language summary\n",
    "    if language not in summary['languages']:\n",
    "        summary['languages'][language] = {'correct': 0, 'wrong': 0, 'inconclusive': 0, 'total': 0}\n",
    "    summary['languages'][language]['total'] += 1\n",
    "    summary['total'] += 1\n",
    "    if final_answer is None:\n",
    "        summary['languages'][language]['inconclusive'] += 1\n",
    "    elif final_answer == label.lower():\n",
    "        summary['languages'][language]['correct'] += 1\n",
    "    else:\n",
    "        summary['languages'][language]['wrong'] += 1\n",
    "\n",
    "    # Save results to CSV iteratively\n",
    "    pd.DataFrame(outputs).to_csv(output_file_path, index=False, encoding='utf-8')\n",
    "\n",
    "    # Save summary to JSON iteratively\n",
    "    with open(summary_file_path, 'w', encoding='utf-8') as file:\n",
    "        json.dump(summary, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Results saved to {output_file_path} and {summary_file_path}\")\n",
    "print(f\"Summary: {summary}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kartvelian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve the OpenAI API key from the environment variable\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Define the prompting method and language family\n",
    "language_family = \"kartvelian\"\n",
    "method = \"direct_inference\"\n",
    "model = \"gpt-4o\"\n",
    "\n",
    "# Load data\n",
    "input_file_path = f'../../Translated JSON Files/{language_family}.json'\n",
    "output_file_path = f\"{language_family}_{model}_{method}.csv\"\n",
    "summary_file_path = f\"{language_family}_{model}_{method}_summary.json\"\n",
    "\n",
    "if os.path.exists(input_file_path):\n",
    "    with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "else:\n",
    "    raise FileNotFoundError(f\"File not found: {input_file_path}\")\n",
    "\n",
    "claims = [item['claim'] for item in data]\n",
    "labels = [item['label'] for item in data]\n",
    "languages = [item['language'] for item in data]\n",
    "sites = [item['site'] for item in data]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'claim': claims,\n",
    "    'label': labels,\n",
    "    'language': languages,\n",
    "    'site': sites\n",
    "})\n",
    "\n",
    "# Language-specific user prompts and final answer mappings\n",
    "prompts = {\n",
    "    \"ka\": \"'{claim}' არის ეს პრეტენზია «მართალია», «ძირითადად მართალია», «ნახევრად მართალია», «ძირითადად მცდარი» ან «მცდარი»? თქვენ ყოველთვის უნდა დარწმუნდეთ, რომ თქვენს საბოლოო პასუხს აქვს პრეფიქსი „საბოლოო პასუხი:“ რასაც მოჰყვება „მართალი“, „ძირითადად მართალია“, „ნახევრად მართალია“, „ძირითადად მცდარი“ ან „მცდარი“.\"\n",
    "}\n",
    "\n",
    "final_answer_mappings = {\n",
    "    \"ka\": {\n",
    "        \"საბოლოო პასუხი: ჭეშმარიტი\": \"true\",\n",
    "        \"საბოლოო პასუხი: უმეტესად ჭეშმარიტი\": \"mostly true\",\n",
    "        \"საბოლოო პასუხი: ნახევრად ჭეშმარიტი\": \"half true\",\n",
    "        \"საბოლოო პასუხი: უმეტესად ცრუ\": \"mostly false\",\n",
    "        \"საბოლოო პასუხი: ცრუ\": \"false\",\n",
    "        \"ჭეშმარიტი\": \"true\",\n",
    "        \"უმეტესად ჭეშმარიტი\": \"mostly true\",\n",
    "        \"ნახევრად ჭეშმარიტი\": \"half true\",\n",
    "        \"უმეტესად ცრუ\": \"mostly false\",\n",
    "        \"ცრუ\": \"false\"\n",
    "    }\n",
    "}\n",
    "\n",
    "def get_gpt_response(claim, language, model=model):\n",
    "    try:\n",
    "        user_prompt = prompts[language].format(claim=claim)\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0,\n",
    "        )\n",
    "        return response['choices'][0]['message']['content']\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting GPT response: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def clean_output(output):\n",
    "    cleaned_output = re.sub(r'[^a-zA-Zა-ჰ\\s:]', '', output)\n",
    "    return cleaned_output.lower()\n",
    "\n",
    "def extract_final_answer(cleaned_output, language):\n",
    "    try:\n",
    "        final_answer = re.search(r'(საბოლოო პასუხი:)\\s*([\\w\\s]+)', cleaned_output)\n",
    "        if final_answer:\n",
    "            response = final_answer.group(2).strip()\n",
    "            for keyword, answer in final_answer_mappings[language].items():\n",
    "                if keyword in response:\n",
    "                    return answer\n",
    "        else:\n",
    "            for keyword, answer in final_answer_mappings[language].items():\n",
    "                if keyword in cleaned_output:\n",
    "                    return answer\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting final answer: {e}\")\n",
    "    return None\n",
    "\n",
    "# Initialize or load existing outputs and summary\n",
    "if os.path.exists(output_file_path)):\n",
    "    output_df = pd.read_csv(output_file_path)\n",
    "    outputs = output_df.to_dict('records')\n",
    "else:\n",
    "    outputs = []\n",
    "\n",
    "if os.path.exists(summary_file_path)):\n",
    "    with open(summary_file_path, 'r', encoding='utf-8') as file:\n",
    "        summary = json.load(file)\n",
    "else:\n",
    "    summary = {\n",
    "        'correct': 0,\n",
    "        'wrong': 0,\n",
    "        'inconclusive': 0,\n",
    "        'total': 0,\n",
    "        'languages': {}\n",
    "    }\n",
    "\n",
    "# Process claims and update files iteratively\n",
    "for index, row in df.iterrows():\n",
    "    if any(output['claim'] == row['claim'] for output in outputs):\n",
    "        continue  # Skip already processed claims\n",
    "\n",
    "    claim = row['claim']\n",
    "    label = row['label']\n",
    "    language = row['language']\n",
    "    \n",
    "    if language not in prompts:  # Skip unsupported languages\n",
    "        continue\n",
    "\n",
    "    output = get_gpt_response(claim, language)\n",
    "    \n",
    "    print(f\"Model Output: {output}\")\n",
    "    \n",
    "    cleaned_output = clean_output(output)\n",
    "    final_answer = extract_final_answer(cleaned_output, language)\n",
    "    \n",
    "    if final_answer is None:\n",
    "        print(\"Inconclusive response\")\n",
    "        summary['inconclusive'] += 1\n",
    "    else:\n",
    "        print(f\"Final Answer: {final_answer.capitalize()}, Actual Answer: {label.capitalize()}\")\n",
    "        if final_answer == label.lower():\n",
    "            print(\"Correct response\")\n",
    "            summary['correct'] += 1\n",
    "        else:\n",
    "            print(\"Wrong response\")\n",
    "            summary['wrong'] += 1\n",
    "    \n",
    "    # Save outputs\n",
    "    output_record = {\n",
    "        'claim': claim,\n",
    "        'label': label,\n",
    "        'language': language,\n",
    "        'output': output,\n",
    "        'final_answer': final_answer,\n",
    "        'correct': final_answer == label.lower() if final_answer else False,\n",
    "        'inconclusive': final_answer is None\n",
    "    }\n",
    "    outputs.append(output_record)\n",
    "    \n",
    "    # Update language summary\n",
    "    if language not in summary['languages']:\n",
    "        summary['languages'][language] = {'correct': 0, 'wrong': 0, 'inconclusive': 0, 'total': 0}\n",
    "    summary['languages'][language]['total'] += 1\n",
    "    summary['total'] += 1\n",
    "    if final_answer is None:\n",
    "        summary['languages'][language]['inconclusive'] += 1\n",
    "    elif final_answer == label.lower():\n",
    "        summary['languages'][language]['correct'] += 1\n",
    "    else:\n",
    "        summary['languages'][language]['wrong'] += 1\n",
    "\n",
    "    # Save results to CSV iteratively\n",
    "    pd.DataFrame(outputs).to_csv(output_file_path, index=False, encoding='utf-8')\n",
    "\n",
    "    # Save summary to JSON iteratively\n",
    "    with open(summary_file_path, 'w', encoding='utf-8') as file:\n",
    "        json.dump(summary, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Results saved to {output_file_path} and {summary_file_path}\")\n",
    "print(f\"Summary: {summary}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slavic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve the OpenAI API key from the environment variable\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Define the prompting method and language family\n",
    "language_family = \"slavic\"\n",
    "method = \"direct_inference\"\n",
    "model = \"gpt-4o\"\n",
    "\n",
    "# Load data\n",
    "input_file_path = f'../../Translated JSON Files/{language_family}.json'\n",
    "output_file_path = f\"{language_family}_{model}_{method}.csv\"\n",
    "summary_file_path = f\"{language_family}_{model}_{method}_summary.json\"\n",
    "\n",
    "if os.path.exists(input_file_path):\n",
    "    with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "else:\n",
    "    raise FileNotFoundError(f\"File not found: {input_file_path}\")\n",
    "\n",
    "claims = [item['claim'] for item in data]\n",
    "labels = [item['label'] for item in data]\n",
    "languages = [item['language'] for item in data]\n",
    "sites = [item['site'] for item in data]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'claim': claims,\n",
    "    'label': labels,\n",
    "    'language': languages,\n",
    "    'site': sites\n",
    "})\n",
    "\n",
    "# Language-specific user prompts and final answer mappings\n",
    "prompts = {\n",
    "    \"ru\": \"'{claim}' является ли это утверждение «правдивым», «в основном правдивым», «наполовину правдивым», «в основном ложным» или «ложным»? Вы должны всегда убедиться, что ваш окончательный ответ начинается с «Окончательный ответ:» и далее следует «Правда», «В основном правда», «Наполовину правда», «В основном ложь» или «Ложь».\",\n",
    "    \"pl\": \"'{claim}' czy to stwierdzenie jest „prawdziwe”, „przeważnie prawdziwe”, „w połowie prawdziwe”, „przeważnie fałszywe” czy „fałszywe”? Musisz zawsze upewnić się, że twoja ostateczna odpowiedź zaczyna się od „Ostateczna odpowiedź:” a następnie „Prawda”, „Przeważnie prawda”, „W połowie prawda”, „Przeważnie fałsz” lub „Fałsz”.\",\n",
    "    \"sr\": \"'{claim}' да ли је ова изјава „истинита”, „углавном истинита”, „полуистинита”, „углавном лажна” или „лажна”? Морате увек осигурати да ваш коначан одговор почиње са „Коначан одговор:” и затим следи „Истина”, „Углавном истина”, „Полуистина”, „Углавном лаж” или „Лаж”.\"\n",
    "}\n",
    "\n",
    "final_answer_mappings = {\n",
    "    \"ru\": {\n",
    "        \"окончательный ответ: правда\": \"true\",\n",
    "        \"окончательный ответ: в основном правда\": \"mostly true\",\n",
    "        \"окончательный ответ: наполовину правда\": \"half true\",\n",
    "        \"окончательный ответ: в основном ложь\": \"mostly false\",\n",
    "        \"окончательный ответ: ложь\": \"false\",\n",
    "        \"правда\": \"true\",\n",
    "        \"в основном правда\": \"mostly true\",\n",
    "        \"наполовину правда\": \"half true\",\n",
    "        \"в основном ложь\": \"mostly false\",\n",
    "        \"ложь\": \"false\"\n",
    "    },\n",
    "    \"pl\": {\n",
    "        \"ostateczna odpowiedź: prawda\": \"true\",\n",
    "        \"ostateczna odpowiedź: przeważnie prawda\": \"mostly true\",\n",
    "        \"ostateczna odpowiedź: w połowie prawda\": \"half true\",\n",
    "        \"ostateczna odpowiedź: przeważnie fałsz\": \"mostly false\",\n",
    "        \"ostateczna odpowiedź: fałsz\": \"false\",\n",
    "        \"prawda\": \"true\",\n",
    "        \"przeważnie prawda\": \"mostly true\",\n",
    "        \"w połowie prawda\": \"half true\",\n",
    "        \"przeważnie fałsz\": \"mostly false\",\n",
    "        \"fałsz\": \"false\"\n",
    "    },\n",
    "    \"sr\": {\n",
    "        \"коначан одговор: истина\": \"true\",\n",
    "        \"коначан одговор: углавном истина\": \"mostly true\",\n",
    "        \"коначан одговор: полуистина\": \"half true\",\n",
    "        \"коначан одговор: углавном лаж\": \"mostly false\",\n",
    "        \"коначан одговор: лаж\": \"false\",\n",
    "        \"истина\": \"true\",\n",
    "        \"углавном истина\": \"mostly true\",\n",
    "        \"полуистина\": \"half true\",\n",
    "        \"углавном лаж\": \"mostly false\",\n",
    "        \"лаж\": \"false\"\n",
    "    }\n",
    "}\n",
    "\n",
    "def get_gpt_response(claim, language, model=model):\n",
    "    try:\n",
    "        user_prompt = prompts[language].format(claim=claim)\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0,\n",
    "        )\n",
    "        return response['choices'][0]['message']['content']\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting GPT response: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def clean_output(output):\n",
    "    cleaned_output = re.sub(r'[^a-zA-Zа-яА-Я\\s:]', '', output)\n",
    "    return cleaned_output.lower()\n",
    "\n",
    "def extract_final_answer(cleaned_output, language):\n",
    "    try:\n",
    "        final_answer = re.search(r'(окончательный ответ:|остateczna odpowiedź:|коначан одговор:)\\s*([\\w\\s]+)', cleaned_output)\n",
    "        if final_answer:\n",
    "            response = final_answer.group(2).strip()\n",
    "            for keyword, answer in final_answer_mappings[language].items():\n",
    "                if keyword in response:\n",
    "                    return answer\n",
    "        else:\n",
    "            for keyword, answer in final_answer_mappings[language].items():\n",
    "                if keyword in cleaned_output:\n",
    "                    return answer\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting final answer: {e}\")\n",
    "    return None\n",
    "\n",
    "# Initialize or load existing outputs and summary\n",
    "if os.path.exists(output_file_path):\n",
    "    output_df = pd.read_csv(output_file_path)\n",
    "    outputs = output_df.to_dict('records')\n",
    "else:\n",
    "    outputs = []\n",
    "\n",
    "if os.path.exists(summary_file_path):\n",
    "    with open(summary_file_path, 'r', encoding='utf-8') as file:\n",
    "        summary = json.load(file)\n",
    "else:\n",
    "    summary = {\n",
    "        'correct': 0,\n",
    "        'wrong': 0,\n",
    "        'inconclusive': 0,\n",
    "        'total': 0,\n",
    "        'languages': {}\n",
    "    }\n",
    "\n",
    "# Process claims and update files iteratively\n",
    "for index, row in df.iterrows():\n",
    "    if any(output['claim'] == row['claim'] for output in outputs):\n",
    "        continue  # Skip already processed claims\n",
    "\n",
    "    claim = row['claim']\n",
    "    label = row['label']\n",
    "    language = row['language']\n",
    "    \n",
    "    if language not in prompts:  # Skip unsupported languages\n",
    "        continue\n",
    "\n",
    "    output = get_gpt_response(claim, language)\n",
    "    \n",
    "    print(f\"Model Output: {output}\")\n",
    "    \n",
    "    cleaned_output = clean_output(output)\n",
    "    final_answer = extract_final_answer(cleaned_output, language)\n",
    "    \n",
    "    if final_answer is None:\n",
    "        print(\"Inconclusive response\")\n",
    "        summary['inconclusive'] += 1\n",
    "    else:\n",
    "        print(f\"Final Answer: {final_answer.capitalize()}, Actual Answer: {label.capitalize()}\")\n",
    "        if final_answer == label.lower():\n",
    "            print(\"Correct response\")\n",
    "            summary['correct'] += 1\n",
    "        else:\n",
    "            print(\"Wrong response\")\n",
    "            summary['wrong'] += 1\n",
    "    \n",
    "    # Save outputs\n",
    "    output_record = {\n",
    "        'claim': claim,\n",
    "        'label': label,\n",
    "        'language': language,\n",
    "        'output': output,\n",
    "        'final_answer': final_answer,\n",
    "        'correct': final_answer == label.lower() if final_answer else False,\n",
    "        'inconclusive': final_answer is None\n",
    "    }\n",
    "    outputs.append(output_record)\n",
    "    \n",
    "    # Update language summary\n",
    "    if language not in summary['languages']:\n",
    "        summary['languages'][language] = {'correct': 0, 'wrong': 0, 'inconclusive': 0, 'total': 0}\n",
    "    summary['languages'][language]['total'] += 1\n",
    "    summary['total'] += 1\n",
    "    if final_answer is None:\n",
    "        summary['languages'][language]['inconclusive'] += 1\n",
    "    elif final_answer == label.lower():\n",
    "        summary['languages'][language]['correct'] += 1\n",
    "    else:\n",
    "        summary['languages'][language]['wrong'] += 1\n",
    "\n",
    "    # Save results to CSV iteratively\n",
    "    pd.DataFrame(outputs).to_csv(output_file_path, index=False, encoding='utf-8')\n",
    "\n",
    "    # Save summary to JSON iteratively\n",
    "    with open(summary_file_path, 'w', encoding='utf-8') as file:\n",
    "        json.dump(summary, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Results saved to {output_file_path} and {summary_file_path}\")\n",
    "print(f\"Summary: {summary}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turkic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve the OpenAI API key from the environment variable\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Define the prompting method and language family\n",
    "language_family = \"turkic\"\n",
    "method = \"direct_inference\"\n",
    "model = \"gpt-4o\"\n",
    "\n",
    "# Load data\n",
    "input_file_path = f'../../Translated JSON Files/{language_family}.json'\n",
    "output_file_path = f\"{language_family}_{model}_{method}.csv\"\n",
    "summary_file_path = f\"{language_family}_{model}_{method}_summary.json\"\n",
    "\n",
    "if os.path.exists(input_file_path):\n",
    "    with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "else:\n",
    "    raise FileNotFoundError(f\"File not found: {input_file_path}\")\n",
    "\n",
    "claims = [item['claim'] for item in data]\n",
    "labels = [item['label'] for item in data]\n",
    "languages = [item['language'] for item in data]\n",
    "sites = [item['site'] for item in data]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'claim': claims,\n",
    "    'label': labels,\n",
    "    'language': languages,\n",
    "    'site': sites\n",
    "})\n",
    "\n",
    "# Language-specific user prompts and final answer mappings\n",
    "prompts = {\n",
    "    \"tr\": \"'{claim}' bu ifade «doğru», «çoğunlukla doğru», «yarı doğru», «çoğunlukla yanlış» veya «yanlış» mı? «Nihai Cevap: Doğru», «Nihai Cevap: Çoğunlukla Doğru», «Nihai Cevap: Yarı Doğru», «Nihai Cevap: Çoğunlukla Yanlış» veya «Nihai Cevap: Yanlış» şeklinde cevap verin.\",\n",
    "    \"az\": \"'{claim}' bu ifadə «doğru», «əsasən doğru», «yarı doğru», «əsasən yanlış» və ya «yanlış»dır? «Son Cavab: Doğru», «Son Cavab: Əsasən Doğru», «Son Cavab: Yarı Doğru», «Son Cavab: Əsasən Yanlış» və ya «Son Cavab: Yanlış» olaraq cavab verin.\"\n",
    "}\n",
    "\n",
    "final_answer_mappings = {\n",
    "    \"tr\": {\n",
    "        \"nihai cevap: doğru\": \"true\",\n",
    "        \"nihai cevap: çoğunlukla doğru\": \"mostly true\",\n",
    "        \"nihai cevap: yarı doğru\": \"half true\",\n",
    "        \"nihai cevap: çoğunlukla yanlış\": \"mostly false\",\n",
    "        \"nihai cevap: yanlış\": \"false\",\n",
    "        \"doğru\": \"true\",\n",
    "        \"çoğunlukla doğru\": \"mostly true\",\n",
    "        \"yarı doğru\": \"half true\",\n",
    "        \"çoğunlukla yanlış\": \"mostly false\",\n",
    "        \"yanlış\": \"false\"\n",
    "    },\n",
    "    \"az\": {\n",
    "        \"son cavab: doğru\": \"true\",\n",
    "        \"son cavab: əsasən doğru\": \"mostly true\",\n",
    "        \"son cavab: yarı doğru\": \"half true\",\n",
    "        \"son cavab: əsasən yanlış\": \"mostly false\",\n",
    "        \"son cavab: yanlış\": \"false\",\n",
    "        \"doğru\": \"true\",\n",
    "        \"əsasən doğru\": \"mostly true\",\n",
    "        \"yarı doğru\": \"half true\",\n",
    "        \"əsasən yanlış\": \"mostly false\",\n",
    "        \"yanlış\": \"false\"\n",
    "    }\n",
    "}\n",
    "\n",
    "def get_gpt_response(claim, language, model=model):\n",
    "    try:\n",
    "        user_prompt = prompts[language].format(claim=claim)\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0,\n",
    "        )\n",
    "        return response['choices'][0]['message']['content']\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting GPT response: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def clean_output(output):\n",
    "    cleaned_output = re.sub(r'[^a-zA-ZəƏıİşŞöÖüÜğĞçÇ\\s:]', '', output)\n",
    "    return cleaned_output.lower()\n",
    "\n",
    "def extract_final_answer(cleaned_output, language):\n",
    "    try:\n",
    "        final_answer = re.search(r'(nihai cevap:|son cavab:)\\s*([\\w\\s]+)', cleaned_output)\n",
    "        if final_answer:\n",
    "            response = final_answer.group(2).strip()\n",
    "            for keyword, answer in final_answer_mappings[language].items():\n",
    "                if keyword in response:\n",
    "                    return answer\n",
    "        else:\n",
    "            for keyword, answer in final_answer_mappings[language].items():\n",
    "                if keyword in cleaned_output:\n",
    "                    return answer\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting final answer: {e}\")\n",
    "    return None\n",
    "\n",
    "# Initialize or load existing outputs and summary\n",
    "if os.path.exists(output_file_path):\n",
    "    output_df = pd.read_csv(output_file_path)\n",
    "    outputs = output_df.to_dict('records')\n",
    "else:\n",
    "    outputs = []\n",
    "\n",
    "if os.path.exists(summary_file_path):\n",
    "    with open(summary_file_path, 'r', encoding='utf-8') as file:\n",
    "        summary = json.load(file)\n",
    "else:\n",
    "    summary = {\n",
    "        'correct': 0,\n",
    "        'wrong': 0,\n",
    "        'inconclusive': 0,\n",
    "        'total': 0,\n",
    "        'languages': {}\n",
    "    }\n",
    "\n",
    "# Process claims and update files iteratively\n",
    "for index, row in df.iterrows():\n",
    "    if any(output['claim'] == row['claim'] for output in outputs):\n",
    "        continue  # Skip already processed claims\n",
    "\n",
    "    claim = row['claim']\n",
    "    label = row['label']\n",
    "    language = row['language']\n",
    "    \n",
    "    if language not in prompts:  # Skip unsupported languages\n",
    "        continue\n",
    "\n",
    "    output = get_gpt_response(claim, language)\n",
    "    \n",
    "    print(f\"Model Output: {output}\")\n",
    "    \n",
    "    cleaned_output = clean_output(output)\n",
    "    final_answer = extract_final_answer(cleaned_output, language)\n",
    "    \n",
    "    if final_answer is None:\n",
    "        print(\"Inconclusive response\")\n",
    "        summary['inconclusive'] += 1\n",
    "    else:\n",
    "        print(f\"Final Answer: {final_answer.capitalize()}, Actual Answer: {label.capitalize()}\")\n",
    "        if final_answer == label.lower():\n",
    "            print(\"Correct response\")\n",
    "            summary['correct'] += 1\n",
    "        else:\n",
    "            print(\"Wrong response\")\n",
    "            summary['wrong'] += 1\n",
    "    \n",
    "    # Save outputs\n",
    "    output_record = {\n",
    "        'claim': claim,\n",
    "        'label': label,\n",
    "        'language': language,\n",
    "        'output': output,\n",
    "        'final_answer': final_answer,\n",
    "        'correct': final_answer == label.lower() if final_answer else False,\n",
    "        'inconclusive': final_answer is None\n",
    "    }\n",
    "    outputs.append(output_record)\n",
    "    \n",
    "    # Update language summary\n",
    "    if language not in summary['languages']:\n",
    "        summary['languages'][language] = {'correct': 0, 'wrong': 0, 'inconclusive': 0, 'total': 0}\n",
    "    summary['languages'][language]['total'] += 1\n",
    "    summary['total'] += 1\n",
    "    if final_answer is None:\n",
    "        summary['languages'][language]['inconclusive'] += 1\n",
    "    elif final_answer == label.lower():\n",
    "        summary['languages'][language]['correct'] += 1\n",
    "    else:\n",
    "        summary['languages'][language]['wrong'] += 1\n",
    "\n",
    "    # Save results to CSV iteratively\n",
    "    pd.DataFrame(outputs).to_csv(output_file_path, index=False, encoding='utf-8')\n",
    "\n",
    "    # Save summary to JSON iteratively\n",
    "    with open(summary_file_path, 'w', encoding='utf-8') as file:\n",
    "        json.dump(summary, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Results saved to {output_file_path} and {summary_file_path}\")\n",
    "print(f\"Summary: {summary}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
