{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Required imports\n","import pandas as pd\n","import openai\n","import json\n","\n","# Define the prompting method and language family\n","language_family = \"germanic\"\n","method = \"direct_inference\"\n","model = \"gpt-3.5-turbo\"\n","\n","with open(f'{language_family}_data.json', 'r', encoding='utf-8') as file:\n","    data = json.load(file)\n","\n","claims = [item['claim'] for item in data]\n","labels = [item['label'] for item in data]\n","\n","df = pd.DataFrame({\n","    'claim': claims,\n","    'label': labels\n","})\n","\n","openai.api_key = '[api_key]'\n","\n","def get_gpt_response(claim, model=model):\n","    system_prompt = f\"\"\n","    user_prompt = f\"'{claim}' Is this claim 'true', 'mostly true', 'half true', 'mostly false', or 'false'? You must always make sure your final response is prefixed with 'Final Answer:' followed by either 'True', 'Mostly True', 'Half True', 'Mostly False', or 'False'.\"\n","    \n","    response = openai.ChatCompletion.create(\n","        model=model,\n","        messages=[\n","            {\"role\": \"system\", \"content\": system_prompt},\n","            {\"role\": \"user\", \"content\": user_prompt}\n","        ],\n","        temperature=0,\n","    )\n","    return response['choices'][0]['message']['content']\n","\n","# Collect model outputs and track results\n","outputs = []\n","correct = 0\n","wrong = 0\n","inconclusive = 0\n","\n","for index, row in df.iterrows():\n","    claim = row['claim']\n","    label = row['label']\n","    output = get_gpt_response(claim, language_family, method=method)\n","    \n","    # Print the model's output\n","    print(f\"Model Output: {output}\")\n","    \n","    # Extract final answer from the output\n","    final_answer = None\n","    if \"final answer: true\" in output.lower():\n","        final_answer = \"true\"\n","    elif \"final answer: false\" in output.lower():\n","        final_answer = \"false\"\n","    elif \"final answer: mostly true\" in output.lower():\n","        final_answer = \"mostly true\"\n","    elif \"final answer: mostly false\" in output.lower():\n","        final_answer = \"mostly false\"\n","    elif \"final answer: half true\" in output.lower():\n","        final_answer = \"half true\"\n","    \n","    # Determine correctness or inconclusiveness\n","    if final_answer is None:\n","        print(\"Inconclusive response\")\n","        inconclusive += 1\n","    else:\n","        print(f\"Final Answer: {final_answer.capitalize()}, Actual Answer: {label.capitalize()}\")\n","        if final_answer == label.lower():\n","            print(\"Correct response\")\n","            correct += 1\n","        else:\n","            print(\"Wrong response\")\n","            wrong += 1\n","    \n","    # Save outputs\n","    outputs.append({\n","        'claim': claim,\n","        'label': label,\n","        'output': output,\n","        'final_answer': final_answer,\n","        'correct': final_answer == label.lower() if final_answer else False,\n","        'inconclusive': final_answer is None\n","    })\n","\n","# Save results to CSV\n","output_df = pd.DataFrame(outputs)\n","output_filename = f\"{language_family}_{model}_{method}.csv\"\n","output_df.to_csv(output_filename, index=False, encoding='utf-8')\n","\n","# Summary of results\n","summary = {\n","    'correct': correct,\n","    'wrong': wrong,\n","    'inconclusive': inconclusive,\n","    'total': len(df)\n","}\n","\n","summary_filename = f\"{language_family}_{model}_{method}_summary.json\"\n","with open(summary_filename, 'w', encoding='utf-8') as file:\n","    json.dump(summary, file, ensure_ascii=False, indent=4)\n","\n","print(f\"Results saved to {output_filename} and {summary_filename}\")\n","print(f\"Summary: {summary}\")\n"]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":2}
