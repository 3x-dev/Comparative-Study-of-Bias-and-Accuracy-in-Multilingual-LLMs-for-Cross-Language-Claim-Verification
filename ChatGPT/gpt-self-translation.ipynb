{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Romance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve the OpenAI API key from the environment variable\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Define the prompting method and language family\n",
    "language_family = \"romance\"\n",
    "method = \"self_translation\"\n",
    "model = \"gpt-3.5-turbo\"\n",
    "\n",
    "# Load data\n",
    "input_file_path = f'JSON Files/{language_family}.json'\n",
    "output_file_path = f\"{language_family}_{model}_{method}.csv\"\n",
    "summary_file_path = f\"{language_family}_{model}_{method}_summary.json\"\n",
    "\n",
    "if os.path.exists(input_file_path):\n",
    "    with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "else:\n",
    "    raise FileNotFoundError(f\"File not found: {input_file_path}\")\n",
    "\n",
    "claims = [item['claim'] for item in data]\n",
    "labels = [item['label'] for item in data]\n",
    "languages = [item['language'] for item in data]\n",
    "sites = [item['site'] for item in data]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'claim': claims,\n",
    "    'label': labels,\n",
    "    'language': languages,\n",
    "    'site': sites\n",
    "})\n",
    "\n",
    "def get_translation(claim, model=model):\n",
    "    user_prompt = f\"Translate the following claim into English: '{claim}'. You must always make sure your final response is prefixed with 'Translated Claim:' followed by the translated claim.\"\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response['choices'][0]['message']['content']\n",
    "\n",
    "def get_gpt_response(translated_claim, model=model):\n",
    "    user_prompt = f\"'{translated_claim}' Is this claim 'True', 'Mostly True', 'Half True', 'Mostly False', or 'False'? You must always make sure your final response is prefixed with 'Final Answer:' followed by either 'True', 'Mostly True', 'Half True', 'Mostly False', or 'False'.\"\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response['choices'][0]['message']['content']\n",
    "\n",
    "# Initialize or load existing outputs and summary\n",
    "if os.path.exists(output_file_path):\n",
    "    output_df = pd.read_csv(output_file_path)\n",
    "    outputs = output_df.to_dict('records')\n",
    "else:\n",
    "    outputs = []\n",
    "\n",
    "if os.path.exists(summary_file_path):\n",
    "    with open(summary_file_path, 'r', encoding='utf-8') as file:\n",
    "        summary = json.load(file)\n",
    "else:\n",
    "    summary = {\n",
    "        'correct': 0,\n",
    "        'wrong': 0,\n",
    "        'inconclusive': 0,\n",
    "        'total': 0,\n",
    "        'languages': {}\n",
    "    }\n",
    "\n",
    "# Function to clean the output text\n",
    "def clean_output(output):\n",
    "    # Extract final answer from the output text\n",
    "    final_answer_match = re.search(r'Final Answer:\\s*(True|Mostly True|Half True|Mostly False|False)', output, re.IGNORECASE)\n",
    "    return final_answer_match.group(1).strip().lower() if final_answer_match else None\n",
    "\n",
    "# Process claims and update files iteratively\n",
    "for index, row in df.iterrows():\n",
    "    if any(output['claim'] == row['claim'] for output in outputs):\n",
    "        continue  # Skip already processed claims\n",
    "\n",
    "    claim = row['claim']\n",
    "    label = row['label']\n",
    "    language = row['language']\n",
    "    \n",
    "    # Translate the claim to English\n",
    "    translated_claim_raw = get_translation(claim)\n",
    "    translated_claim_match = re.search(r'Translated Claim:\\s*(.*)', translated_claim_raw, re.IGNORECASE)\n",
    "    translated_claim = translated_claim_match.group(1) if translated_claim_match else None\n",
    "    print(f\"Original Claim: {claim}\")\n",
    "    print(f\"Translated Claim: {translated_claim_raw}\")\n",
    "\n",
    "    if translated_claim is None:\n",
    "        print(\"Error: Translated claim not found.\")\n",
    "        continue\n",
    "    \n",
    "    # Evaluate the translated claim\n",
    "    output_raw = get_gpt_response(translated_claim)\n",
    "    print(f\"Model Output: {output_raw}\")\n",
    "    \n",
    "    # Extract final answer from the cleaned output\n",
    "    final_answer = clean_output(output_raw)\n",
    "    \n",
    "    # Determine correctness or inconclusiveness\n",
    "    if final_answer is None:\n",
    "        print(\"Inconclusive response\")\n",
    "        summary['inconclusive'] += 1\n",
    "    else:\n",
    "        print(f\"Final Answer: {final_answer.capitalize()}, Actual Answer: {label.capitalize()}\")\n",
    "        if final_answer == label.lower():\n",
    "            print(\"Correct response\")\n",
    "            summary['correct'] += 1\n",
    "        else:\n",
    "            print(\"Wrong response\")\n",
    "            summary['wrong'] += 1\n",
    "    \n",
    "    # Save outputs\n",
    "    output_record = {\n",
    "        'claim': claim,\n",
    "        'label': label,\n",
    "        'language': language,\n",
    "        'translated_claim': translated_claim,\n",
    "        'output': output_raw,\n",
    "        'final_answer': final_answer,\n",
    "        'correct': final_answer == label.lower() if final_answer else False,\n",
    "        'inconclusive': final_answer is None\n",
    "    }\n",
    "    outputs.append(output_record)\n",
    "    \n",
    "    # Update language summary\n",
    "    if language not in summary['languages']:\n",
    "        summary['languages'][language] = {'correct': 0, 'wrong': 0, 'inconclusive': 0, 'total': 0}\n",
    "    summary['languages'][language]['total'] += 1\n",
    "    summary['total'] += 1\n",
    "    if final_answer is None:\n",
    "        summary['languages'][language]['inconclusive'] += 1\n",
    "    elif final_answer == label.lower():\n",
    "        summary['languages'][language]['correct'] += 1\n",
    "    else:\n",
    "        summary['languages'][language]['wrong'] += 1\n",
    "\n",
    "    # Save results to CSV iteratively\n",
    "    pd.DataFrame(outputs).to_csv(output_file_path, index=False, encoding='utf-8')\n",
    "\n",
    "    # Save summary to JSON iteratively\n",
    "    with open(summary_file_path, 'w', encoding='utf-8') as file:\n",
    "        json.dump(summary, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Results saved to {output_file_path} and {summary_file_path}\")\n",
    "print(f\"Summary: {summary}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
