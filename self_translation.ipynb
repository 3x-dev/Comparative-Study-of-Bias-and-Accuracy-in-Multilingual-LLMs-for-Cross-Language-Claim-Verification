{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "Ve49ddH0JyS0",
        "outputId": "df380692-6662-4c77-9a45-9267aa00e810"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'germanic_data.json'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-a2c033bd4b29>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{language_family}_data.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'germanic_data.json'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import openai\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Retrieve the OpenAI API key from the environment variable\n",
        "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
        "\n",
        "# Define the prompting method and language family\n",
        "language_family = \"english\"\n",
        "method = \"direct_inference\"\n",
        "model = \"gpt-3.5-turbo\"\n",
        "\n",
        "# Load data\n",
        "input_file_path = f'JSON Files/{language_family}.json'\n",
        "output_file_path = f\"{language_family}_{model}_{method}.csv\"\n",
        "summary_file_path = f\"{language_family}_{model}_{method}_summary.json\"\n",
        "\n",
        "if os.path.exists(input_file_path):\n",
        "    with open(input_file_path, 'r', encoding='utf-8') as file:\n",
        "        data = json.load(file)\n",
        "else:\n",
        "    raise FileNotFoundError(f\"File not found: {input_file_path}\")\n",
        "\n",
        "claims = [item['claim'] for item in data]\n",
        "labels = [item['label'] for item in data]\n",
        "languages = [item['language'] for item in data]\n",
        "sites = [item['site'] for item in data]\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'claim': claims,\n",
        "    'label': labels,\n",
        "    'language': languages,\n",
        "    'site': sites\n",
        "})\n",
        "\n",
        "def translate(claim, model=model):\n",
        "   system_prompt = \"\"\n",
        "\n",
        "\n",
        "   translate_prompt = f\"'{claim}' Translate this claim to English.\"\n",
        "\n",
        "\n",
        "   translation = openai.ChatCompletion.create(\n",
        "       model=model,\n",
        "       messages=[\n",
        "           {\"role\": \"system\", \"content\": system_prompt},\n",
        "           {\"role\": \"user\", \"content\": translate_prompt}\n",
        "       ],\n",
        "       temperature=0,\n",
        "   )\n",
        "   return translation['choices'][0]['message']['content']\n",
        "\n",
        "def get_gpt_response(claim, model=model):\n",
        "    translated_claim = translate(claim)\n",
        "\n",
        "    system_prompt = \"\"\n",
        "\n",
        "    user_prompt = f\"'{translated_claim}' Is this claim 'true', 'mostly true', 'half true', 'mostly false', or 'false'? You must always make sure your final response is prefixed with 'Final Answer:' followed by either 'True', 'Mostly True', 'Half True', 'Mostly False', or 'False'.\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_prompt}\n",
        "        ],\n",
        "        temperature=0,\n",
        "    )\n",
        "    return response['choices'][0]['message']['content']\n",
        "\n",
        "# Initialize or load existing outputs and summary\n",
        "if os.path.exists(output_file_path):\n",
        "    output_df = pd.read_csv(output_file_path)\n",
        "    outputs = output_df.to_dict('records')\n",
        "else:\n",
        "    outputs = []\n",
        "\n",
        "if os.path.exists(summary_file_path):\n",
        "    with open(summary_file_path, 'r', encoding='utf-8') as file:\n",
        "        summary = json.load(file)\n",
        "else:\n",
        "    summary = {\n",
        "        'correct': 0,\n",
        "        'wrong': 0,\n",
        "        'inconclusive': 0,\n",
        "        'total': 0,\n",
        "        'languages': {}\n",
        "    }\n",
        "\n",
        "# Function to clean the output text\n",
        "def clean_output(output):\n",
        "    # Remove non-alphanumeric characters except spaces\n",
        "    cleaned_output = re.sub(r'[^a-zA-Z\\s]', '', output)\n",
        "    return cleaned_output\n",
        "\n",
        "# Process claims and update files iteratively\n",
        "for index, row in df.iterrows():\n",
        "    if any(output['claim'] == row['claim'] for output in outputs):\n",
        "        continue  # Skip already processed claims\n",
        "\n",
        "    claim = row['claim']\n",
        "    label = row['label']\n",
        "    language = row['language']\n",
        "    output = get_gpt_response(claim)\n",
        "    \n",
        "    # Print the model's output\n",
        "    print(f\"Model Output: {output}\")\n",
        "    \n",
        "    # Clean the output\n",
        "    cleaned_output = clean_output(output)\n",
        "    \n",
        "    # Extract final answer from the cleaned output\n",
        "    final_answer = None\n",
        "    if \"final answer true\" in cleaned_output.lower():\n",
        "        final_answer = \"true\"\n",
        "    elif \"final answer false\" in cleaned_output.lower():\n",
        "        final_answer = \"false\"\n",
        "    elif \"final answer mostly true\" in cleaned_output.lower():\n",
        "        final_answer = \"mostly true\"\n",
        "    elif \"final answer mostly false\" in cleaned_output.lower():\n",
        "        final_answer = \"mostly false\"\n",
        "    elif \"final answer half true\" in cleaned_output.lower():\n",
        "        final_answer = \"half true\"\n",
        "    \n",
        "    # Determine correctness or inconclusiveness\n",
        "    if final_answer is None:\n",
        "        print(\"Inconclusive response\")\n",
        "        summary['inconclusive'] += 1\n",
        "    else:\n",
        "        print(f\"Final Answer: {final_answer.capitalize()}, Actual Answer: {label.capitalize()}\")\n",
        "        if final_answer == label.lower():\n",
        "            print(\"Correct response\")\n",
        "            summary['correct'] += 1\n",
        "        else:\n",
        "            print(\"Wrong response\")\n",
        "            summary['wrong'] += 1\n",
        "    \n",
        "    # Save outputs\n",
        "    output_record = {\n",
        "        'claim': claim,\n",
        "        'label': label,\n",
        "        'language': language,\n",
        "        'output': output,\n",
        "        'final_answer': final_answer,\n",
        "        'correct': final_answer == label.lower() if final_answer else False,\n",
        "        'inconclusive': final_answer is None\n",
        "    }\n",
        "    outputs.append(output_record)\n",
        "    \n",
        "    # Update language summary\n",
        "    if language not in summary['languages']:\n",
        "        summary['languages'][language] = {'correct': 0, 'wrong': 0, 'inconclusive': 0, 'total': 0}\n",
        "    summary['languages'][language]['total'] += 1\n",
        "    summary['total'] += 1\n",
        "    if final_answer is None:\n",
        "        summary['languages'][language]['inconclusive'] += 1\n",
        "    elif final_answer == label.lower():\n",
        "        summary['languages'][language]['correct'] += 1\n",
        "    else:\n",
        "        summary['languages'][language]['wrong'] += 1\n",
        "\n",
        "    # Save results to CSV iteratively\n",
        "    pd.DataFrame(outputs).to_csv(output_file_path, index=False, encoding='utf-8')\n",
        "\n",
        "    # Save summary to JSON iteratively\n",
        "    with open(summary_file_path, 'w', encoding='utf-8') as file:\n",
        "        json.dump(summary, file, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f\"Results saved to {output_file_path} and {summary_file_path}\")\n",
        "print(f\"Summary: {summary}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
